{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def init(std):\n",
    "    np.random.seed(42)\n",
    "    x = np.empty(1505)\n",
    "    y = np.empty(1505)\n",
    "\n",
    "    x[0]=1.5\n",
    "    y[0]=0\n",
    "\n",
    "    for i in range(1500):\n",
    "        if i<25:\n",
    "            x[i+1] = x[i] - 0.1*x[i]\n",
    "\n",
    "        else:\n",
    "            x[i+1] = x[i] + ((0.2*x[i-25])/(1+pow(x[i-25],10))) - 0.1*x[i]\n",
    "        y[i+1]=i\n",
    "\n",
    "\n",
    "    noise = np.random.normal(0,std,1505)\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        x[i]=x[i]+noise[i]\n",
    "\n",
    "    #plt.plot(y[:1500],x[:1500],'-')\n",
    "    #plt.show()\n",
    "    \n",
    "    inp=[]\n",
    "    out=[]\n",
    "\n",
    "    for i in range(300,1500):\n",
    "        inp.append([x[i-20], x[i-15], x[i-10], x[i-5], x[i]])\n",
    "        out.append(x[i+5])\n",
    "        \n",
    "\n",
    "    train_X = np.array(inp[0:800])\n",
    "    train_y = np.array(out[0:800])\n",
    "\n",
    "    val_X = np.array(inp[800:1000])\n",
    "    val_y = np.array(out[800:1000])\n",
    "\n",
    "    test_X = np.array(inp[1000:])\n",
    "    test_y = np.array(out[1000:])\n",
    "    \n",
    "    return train_X, train_y, val_X, val_y, test_X, test_y, x, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single layer network: \n",
      "Number of nodes:  1  Time:  16.684641576954164\n",
      "Number of nodes:  2  Time:  14.14437537296908\n",
      "Number of nodes:  3  Time:  14.449179476010613\n",
      "Number of nodes:  4  Time:  14.25004405301297\n",
      "Number of nodes:  5  Time:  11.281834467023145\n",
      "Number of nodes:  6  Time:  11.176124380959664\n",
      "Number of nodes:  7  Time:  11.216532215999905\n",
      "Number of nodes:  8  Time:  11.198172483011149\n",
      "\n",
      "Multi layer network: \n",
      "Number of nodes in first:  1 Number of nodes in second:  1  Time:  17.591064815002028\n",
      "Number of nodes in first:  1 Number of nodes in second:  2  Time:  12.212944911967497\n",
      "Number of nodes in first:  1 Number of nodes in second:  3  Time:  11.999207639019005\n",
      "Number of nodes in first:  1 Number of nodes in second:  4  Time:  11.896727633022238\n",
      "Number of nodes in first:  1 Number of nodes in second:  5  Time:  12.177229719003662\n",
      "Number of nodes in first:  1 Number of nodes in second:  6  Time:  12.573984046000987\n",
      "Number of nodes in first:  1 Number of nodes in second:  7  Time:  12.085656965966336\n",
      "Number of nodes in first:  1 Number of nodes in second:  8  Time:  12.175723173015285\n",
      "Number of nodes in first:  2 Number of nodes in second:  1  Time:  12.148015976999886\n",
      "Number of nodes in first:  2 Number of nodes in second:  2  Time:  12.017359543009661\n",
      "Number of nodes in first:  2 Number of nodes in second:  3  Time:  15.372328008990735\n",
      "Number of nodes in first:  2 Number of nodes in second:  4  Time:  12.579836969962344\n",
      "Number of nodes in first:  2 Number of nodes in second:  5  Time:  12.285767839988694\n",
      "Number of nodes in first:  2 Number of nodes in second:  6  Time:  13.926032862975262\n",
      "Number of nodes in first:  2 Number of nodes in second:  7  Time:  12.671374656027183\n",
      "Number of nodes in first:  2 Number of nodes in second:  8  Time:  12.419106799992733\n",
      "Number of nodes in first:  3 Number of nodes in second:  1  Time:  14.30572210502578\n",
      "Number of nodes in first:  3 Number of nodes in second:  2  Time:  20.359368075965904\n",
      "Number of nodes in first:  3 Number of nodes in second:  3  Time:  28.55301390000386\n",
      "Number of nodes in first:  3 Number of nodes in second:  4  Time:  21.54568850900978\n",
      "Number of nodes in first:  3 Number of nodes in second:  5  Time:  18.94421628303826\n",
      "Number of nodes in first:  3 Number of nodes in second:  6  Time:  22.595477066992316\n",
      "Number of nodes in first:  3 Number of nodes in second:  7  Time:  27.26189094601432\n",
      "Number of nodes in first:  3 Number of nodes in second:  8  Time:  17.689418822003063\n",
      "Number of nodes in first:  4 Number of nodes in second:  1  Time:  17.091689663007855\n",
      "Number of nodes in first:  4 Number of nodes in second:  2  Time:  23.25833869498456\n",
      "Number of nodes in first:  4 Number of nodes in second:  3  Time:  19.893140401982237\n",
      "Number of nodes in first:  4 Number of nodes in second:  4  Time:  15.700312395987567\n",
      "Number of nodes in first:  4 Number of nodes in second:  5  Time:  15.627564188966062\n",
      "Number of nodes in first:  4 Number of nodes in second:  6  Time:  16.19249943003524\n",
      "Number of nodes in first:  4 Number of nodes in second:  7  Time:  19.50381527194986\n",
      "Number of nodes in first:  4 Number of nodes in second:  8  Time:  20.607062453986146\n",
      "Number of nodes in first:  5 Number of nodes in second:  1  Time:  19.644231280020904\n",
      "Number of nodes in first:  5 Number of nodes in second:  2  Time:  16.48217182297958\n",
      "Number of nodes in first:  5 Number of nodes in second:  3  Time:  15.954129220976029\n",
      "Number of nodes in first:  5 Number of nodes in second:  4  Time:  16.075101514987182\n",
      "Number of nodes in first:  5 Number of nodes in second:  5  Time:  35.67633644799935\n",
      "Number of nodes in first:  5 Number of nodes in second:  6  Time:  19.61008369200863\n",
      "Number of nodes in first:  5 Number of nodes in second:  7  Time:  16.528704466007184\n",
      "Number of nodes in first:  5 Number of nodes in second:  8  Time:  17.219568872009404\n",
      "Number of nodes in first:  6 Number of nodes in second:  1  Time:  16.837573029042687\n",
      "Number of nodes in first:  6 Number of nodes in second:  2  Time:  18.279369964962825\n",
      "Number of nodes in first:  6 Number of nodes in second:  3  Time:  23.9457779499935\n",
      "Number of nodes in first:  6 Number of nodes in second:  4  Time:  18.812325276026968\n",
      "Number of nodes in first:  6 Number of nodes in second:  5  Time:  19.457951840013266\n",
      "Number of nodes in first:  6 Number of nodes in second:  6  Time:  18.600068157014903\n",
      "Number of nodes in first:  6 Number of nodes in second:  7  Time:  35.45852181100054\n",
      "Number of nodes in first:  6 Number of nodes in second:  8  Time:  22.15228797798045\n",
      "Number of nodes in first:  7 Number of nodes in second:  1  Time:  29.769048510002904\n",
      "Number of nodes in first:  7 Number of nodes in second:  2  Time:  23.300548901956063\n",
      "Number of nodes in first:  7 Number of nodes in second:  3  Time:  20.07320849003736\n",
      "Number of nodes in first:  7 Number of nodes in second:  4  Time:  18.46157951001078\n",
      "Number of nodes in first:  7 Number of nodes in second:  5  Time:  21.515336678014137\n",
      "Number of nodes in first:  7 Number of nodes in second:  6  Time:  24.749040530994534\n",
      "Number of nodes in first:  7 Number of nodes in second:  7  Time:  19.435299277014565\n",
      "Number of nodes in first:  7 Number of nodes in second:  8  Time:  17.26035373302875\n",
      "Number of nodes in first:  8 Number of nodes in second:  1  Time:  17.18350487103453\n",
      "Number of nodes in first:  8 Number of nodes in second:  2  Time:  23.671490017033648\n",
      "Number of nodes in first:  8 Number of nodes in second:  3  Time:  19.99057864904171\n",
      "Number of nodes in first:  8 Number of nodes in second:  4  Time:  20.40385572402738\n",
      "Number of nodes in first:  8 Number of nodes in second:  5  Time:  18.36148767999839\n",
      "Number of nodes in first:  8 Number of nodes in second:  6  Time:  19.44265985104721\n",
      "Number of nodes in first:  8 Number of nodes in second:  7  Time:  18.63081331801368\n",
      "Number of nodes in first:  8 Number of nodes in second:  8  Time:  26.344793216965627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def neural_network_first(std, num_nodes_first,reg_cons,batch_size):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    train_X, train_y, val_X, val_y, test_X, test_y, x, y = init(std)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_nodes_first, input_dim=5, kernel_regularizer=l2(reg_cons), activation='relu'))\n",
    "    #model.add(Dense(num_nodes_second, kernel_regularizer=l2(reg_cons), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mae'])\n",
    "    #earlystopping = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=1, verbose=0, mode='auto')\n",
    "    start = timeit.default_timer()\n",
    "    model.fit(train_X, train_y, epochs=20, batch_size=batch_size, validation_data=(val_X, val_y),verbose=0, shuffle=False)\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop-start\n",
    "    predictions = np.array(model.predict(test_X))\n",
    "    #plt.plot( y[1300:1500],predictions,'-',label='Predicted')\n",
    "    #plt.plot( y[1300:1500],x[1300:1500],'-',label='True')\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "    \n",
    "    ## Större värde på konstanten reg_cons gör att inlärningen blir mer generell och man tar mindre hänsyn till extremerna\n",
    "    ## Batch size tycks också påverka hur generell inlärningen blir. Varför?\n",
    "    ## Num nodes får labbas fram för bäst resultat :) \n",
    "    \n",
    "    \n",
    "    mse = mean_squared_error(predictions, x[1300:1500])\n",
    "    #print(\"STD: \", std,\" MSE: \", mse)\n",
    "    print(\"Number of nodes: \", num_nodes_first, \" Time: \",time)\n",
    "    return mse\n",
    "\n",
    "def neural_network_second(std, num_nodes_first,num_nodes_second,reg_cons,batch_size):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    train_X, train_y, val_X, val_y, test_X, test_y, x, y = init(std)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_nodes_first, input_dim=5, kernel_regularizer=l2(reg_cons), activation='relu'))\n",
    "    model.add(Dense(num_nodes_second, kernel_regularizer=l2(reg_cons), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mae'])\n",
    "    #earlystopping = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=1, verbose=0, mode='auto')\n",
    "    start = timeit.default_timer()\n",
    "    model.fit(train_X, train_y, epochs=20, batch_size=batch_size, validation_data=(val_X, val_y),verbose=0, shuffle=False)\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop-start\n",
    "    \n",
    "    predictions = np.array(model.predict(test_X))\n",
    "    #plt.plot( y[1300:1500],predictions,'-',label='Predicted')\n",
    "    #plt.plot( y[1300:1500],x[1300:1500],'-',label='True')\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "    \n",
    "    ## Större värde på konstanten reg_cons gör att inlärningen blir mer generell och man tar mindre hänsyn till extremerna\n",
    "    ## Batch size tycks också påverka hur generell inlärningen blir. Varför?\n",
    "    ## Num nodes får labbas fram för bäst resultat :) \n",
    "    \n",
    "    \n",
    "    mse = mean_squared_error(predictions, x[1300:1500])\n",
    "    #print(\"STD: \", std,\" MSE: \", mse)\n",
    "    print(\"Number of nodes in first: \", num_nodes_first,\"Number of nodes in second: \", num_nodes_second, \" Time: \",time)\n",
    "    return mse\n",
    "    \n",
    "        \n",
    "\n",
    "y1=[]\n",
    "x1=[]\n",
    "y2=[]\n",
    "x2=[]\n",
    "y3=[]\n",
    "x3=[]\n",
    "\n",
    "print(\"Single layer network: \")\n",
    "for i in range(1,9):\n",
    "    neural_network_first(std=0.09,num_nodes_first=i, reg_cons=0.0001 , batch_size=32)\n",
    "    \n",
    "print(\"\\nMulti layer network: \")\n",
    "for i in range(1,9):\n",
    "    for j in range(1,9):\n",
    "        neural_network_second(std=0.09,num_nodes_first=i,num_nodes_second=j, reg_cons=0.0001 , batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.plot(x1,y1,\\'-\\', label=\\'STDdev = 0.03\\')\\nplt.xlabel(\\'Number of nodes:\\')\\nplt.ylabel(\\'MSE\\')\\nplt.legend()\\nplt.show()\\nprint(\"Mean MSE: \", np.mean(y1))\\n\\nplt.plot(x2,y2,\\'-\\', label=\\'STDdev = 0.09\\')\\nplt.xlabel(\\'Number of nodes:\\')\\nplt.ylabel(\\'MSE\\')\\nplt.legend()\\nplt.show()\\nprint(\"Mean MSE: \",np.mean(y2))\\n\\nplt.plot(x3,y3,\\'-\\', label=\\'STDdev = 0.18\\')\\nplt.xlabel(\\'Number of nodes:\\')\\nplt.ylabel(\\'MSE\\')\\nplt.legend()\\nplt.show()\\nprint(\"Mean MSE: \",np.mean(y3))'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"plt.plot(x1,y1,'-', label='STDdev = 0.03')\n",
    "plt.xlabel('Number of nodes:')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Mean MSE: \", np.mean(y1))\n",
    "\n",
    "plt.plot(x2,y2,'-', label='STDdev = 0.09')\n",
    "plt.xlabel('Number of nodes:')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Mean MSE: \",np.mean(y2))\n",
    "\n",
    "plt.plot(x3,y3,'-', label='STDdev = 0.18')\n",
    "plt.xlabel('Number of nodes:')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Mean MSE: \",np.mean(y3))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(1,9):\\n    y1.append(neural_network(std=0.03,num_nodes_first=8,num_nodes_second=i, reg_cons=0.0001 , batch_size=32))\\n    x1.append(i)\\n\\nfor i in range(1,9):\\n    y2.append(neural_network(std=0.09,num_nodes_first=8,num_nodes_second=i, reg_cons=0.0001 , batch_size=32))\\n    x2.append(i)\\n    \\nfor i in range(1,9):\\n    y3.append(neural_network(std=0.18,num_nodes_first=8,num_nodes_second=i, reg_cons=0.0001 , batch_size=32))\\n    x3.append(i)\\n\\n\\nprint(\"\\nSTD: 0.03\")\\ny1.append(neural_network(std=0.03,num_nodes_first=8,num_nodes_second=1, reg_cons=0.00001 , batch_size=32))\\ny1.append(neural_network(std=0.03,num_nodes_first=8,num_nodes_second=1, reg_cons=0.0001 , batch_size=32))\\ny1.append(neural_network(std=0.03,num_nodes_first=8,num_nodes_second=1, reg_cons=0.001 , batch_size=32))\\ny1.append(neural_network(std=0.03,num_nodes_first=8,num_nodes_second=1, reg_cons=0.01 , batch_size=32))\\ny1.append(neural_network(std=0.03,num_nodes_first=8,num_nodes_second=1, reg_cons=0.1 , batch_size=32))\\n\\nprint(\"\\nSTD: 0.09\")\\ny1.append(neural_network(std=0.09,num_nodes_first=8,num_nodes_second=1, reg_cons=0.00001 , batch_size=32))\\ny1.append(neural_network(std=0.09,num_nodes_first=8,num_nodes_second=1, reg_cons=0.0001 , batch_size=32))\\ny1.append(neural_network(std=0.09,num_nodes_first=8,num_nodes_second=1, reg_cons=0.001 , batch_size=32))\\ny1.append(neural_network(std=0.09,num_nodes_first=8,num_nodes_second=1, reg_cons=0.01 , batch_size=32))\\ny1.append(neural_network(std=0.09,num_nodes_first=8,num_nodes_second=1, reg_cons=0.1 , batch_size=32))\\n\\n\\nprint(\"\\nSTD: 0.18\")\\ny1.append(neural_network(std=0.18,num_nodes_first=8,num_nodes_second=1, reg_cons=0.00001 , batch_size=32))\\ny1.append(neural_network(std=0.18,num_nodes_first=8,num_nodes_second=1, reg_cons=0.0001 , batch_size=32))\\ny1.append(neural_network(std=0.18,num_nodes_first=8,num_nodes_second=1, reg_cons=0.001 , batch_size=32))\\ny1.append(neural_network(std=0.18,num_nodes_first=8,num_nodes_second=1, reg_cons=0.01 , batch_size=32))\\ny1.append(neural_network(std=0.18,num_nodes_first=8,num_nodes_second=1, reg_cons=0.1 , batch_size=32))\\n\\n\\nprint(\"\\nSTD: 0.36\")\\ny1.append(neural_network(std=0.36,num_nodes_first=8,num_nodes_second=1, reg_cons=0.00001 , batch_size=32))\\ny1.append(neural_network(std=0.36,num_nodes_first=8,num_nodes_second=1, reg_cons=0.0001 , batch_size=32))\\ny1.append(neural_network(std=0.36,num_nodes_first=8,num_nodes_second=1, reg_cons=0.001 , batch_size=32))\\ny1.append(neural_network(std=0.36,num_nodes_first=8,num_nodes_second=1, reg_cons=0.01 , batch_size=32))\\ny1.append(neural_network(std=0.36,num_nodes_first=8,num_nodes_second=1, reg_cons=0.1 , batch_size=32))\\n\\nprint(\"\\nSTD: 0.72\")\\ny1.append(neural_network(std=0.72,num_nodes_first=8,num_nodes_second=1, reg_cons=0.00001 , batch_size=32))\\ny1.append(neural_network(std=0.72,num_nodes_first=8,num_nodes_second=1, reg_cons=0.0001 , batch_size=32))\\ny1.append(neural_network(std=0.72,num_nodes_first=8,num_nodes_second=1, reg_cons=0.001 , batch_size=32))\\ny1.append(neural_network(std=0.72,num_nodes_first=8,num_nodes_second=1, reg_cons=0.01 , batch_size=32))\\ny1.append(neural_network(std=0.72,num_nodes_first=8,num_nodes_second=1, reg_cons=0.1 , batch_size=32))\\n\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "print(\"\\nSingle layer network: \")\n",
    "neural_network_first(std=0.03,num_nodes_first=8, reg_cons=0.0001 , batch_size=32)\n",
    "neural_network_first(std=0.09,num_nodes_first=8, reg_cons=0.0001 , batch_size=32)\n",
    "neural_network_first(std=0.18,num_nodes_first=8, reg_cons=0.0001 , batch_size=32)\n",
    "\n",
    "print(\"\\nDouble layer network: \")\n",
    "neural_network_second(std=0.03,num_nodes_first=8, num_nodes_second=1, reg_cons=0.0001 , batch_size=32)\n",
    "neural_network_second(std=0.09,num_nodes_first=8, num_nodes_second=1, reg_cons=0.0001 , batch_size=32)\n",
    "neural_network_second(std=0.18,num_nodes_first=8, num_nodes_second=1, reg_cons=0.0001 , batch_size=32)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for i in range(1,9):\n",
    "    y1.append(neural_network(std=0.03,num_nodes_first=8,num_nodes_second=i, reg_cons=0.0001 , batch_size=32))\n",
    "    x1.append(i)\n",
    "\n",
    "for i in range(1,9):\n",
    "    y2.append(neural_network(std=0.09,num_nodes_first=8,num_nodes_second=i, reg_cons=0.0001 , batch_size=32))\n",
    "    x2.append(i)\n",
    "    \n",
    "for i in range(1,9):\n",
    "    y3.append(neural_network(std=0.18,num_nodes_first=8,num_nodes_second=i, reg_cons=0.0001 , batch_size=32))\n",
    "    x3.append(i)\n",
    "\n",
    "\n",
    "print(\"\\nSTD: 0.03\")\n",
    "y1.append(neural_network(std=0.03,num_nodes_first=8,num_nodes_second=1, reg_cons=0.00001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.03,num_nodes_first=8,num_nodes_second=1, reg_cons=0.0001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.03,num_nodes_first=8,num_nodes_second=1, reg_cons=0.001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.03,num_nodes_first=8,num_nodes_second=1, reg_cons=0.01 , batch_size=32))\n",
    "y1.append(neural_network(std=0.03,num_nodes_first=8,num_nodes_second=1, reg_cons=0.1 , batch_size=32))\n",
    "\n",
    "print(\"\\nSTD: 0.09\")\n",
    "y1.append(neural_network(std=0.09,num_nodes_first=8,num_nodes_second=1, reg_cons=0.00001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.09,num_nodes_first=8,num_nodes_second=1, reg_cons=0.0001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.09,num_nodes_first=8,num_nodes_second=1, reg_cons=0.001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.09,num_nodes_first=8,num_nodes_second=1, reg_cons=0.01 , batch_size=32))\n",
    "y1.append(neural_network(std=0.09,num_nodes_first=8,num_nodes_second=1, reg_cons=0.1 , batch_size=32))\n",
    "\n",
    "\n",
    "print(\"\\nSTD: 0.18\")\n",
    "y1.append(neural_network(std=0.18,num_nodes_first=8,num_nodes_second=1, reg_cons=0.00001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.18,num_nodes_first=8,num_nodes_second=1, reg_cons=0.0001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.18,num_nodes_first=8,num_nodes_second=1, reg_cons=0.001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.18,num_nodes_first=8,num_nodes_second=1, reg_cons=0.01 , batch_size=32))\n",
    "y1.append(neural_network(std=0.18,num_nodes_first=8,num_nodes_second=1, reg_cons=0.1 , batch_size=32))\n",
    "\n",
    "\n",
    "print(\"\\nSTD: 0.36\")\n",
    "y1.append(neural_network(std=0.36,num_nodes_first=8,num_nodes_second=1, reg_cons=0.00001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.36,num_nodes_first=8,num_nodes_second=1, reg_cons=0.0001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.36,num_nodes_first=8,num_nodes_second=1, reg_cons=0.001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.36,num_nodes_first=8,num_nodes_second=1, reg_cons=0.01 , batch_size=32))\n",
    "y1.append(neural_network(std=0.36,num_nodes_first=8,num_nodes_second=1, reg_cons=0.1 , batch_size=32))\n",
    "\n",
    "print(\"\\nSTD: 0.72\")\n",
    "y1.append(neural_network(std=0.72,num_nodes_first=8,num_nodes_second=1, reg_cons=0.00001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.72,num_nodes_first=8,num_nodes_second=1, reg_cons=0.0001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.72,num_nodes_first=8,num_nodes_second=1, reg_cons=0.001 , batch_size=32))\n",
    "y1.append(neural_network(std=0.72,num_nodes_first=8,num_nodes_second=1, reg_cons=0.01 , batch_size=32))\n",
    "y1.append(neural_network(std=0.72,num_nodes_first=8,num_nodes_second=1, reg_cons=0.1 , batch_size=32))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
