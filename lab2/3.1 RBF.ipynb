{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch mode training using least squares - supervised learning of network weights. \n",
    "\n",
    "\n",
    "- Implement a radial basis function network from scratch. \n",
    "\n",
    "- The network will be used to approximate sin(2x) and square(2x) functions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Support functions for the evaluation\n",
    "\n",
    "def getTrainSet(func = 'sin2x', stepSize = 0.1):\n",
    "    ## Returns an 2 x N array of a training set\n",
    "    # Row 0 = inputs and row 1 = targets¨\n",
    "    # stepSize is taken as input, range is fixed to 0 --> 2pi. \n",
    "    N = int(np.floor(2 * np.pi/stepSize)) #Number of datapoints\n",
    "    \n",
    "    train = np.zeros((2,N))\n",
    "    inputs = np.arange(0, N)\n",
    "    np.random.shuffle(inputs)\n",
    "    \n",
    "    for step, i in enumerate(inputs):\n",
    "        train[0, i] = step*stepSize # Input: will be for example 0, 0.1, 0.2 .. 2pi etc.. \n",
    "        if (func == 'sin2x'): \n",
    "            train[1, i] = np.sin(2*step*stepSize) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "        elif (func == 'step2x'): \n",
    "            train[1, i] = np.sign(np.sin(2*step*stepSize)) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "\n",
    "    return train.T\n",
    "\n",
    "def getTestSet(func = 'sin2x', stepSize = 0.1):\n",
    "    ## Returns an 2 x N array of a training set\n",
    "    # Row 0 = inputs and row 1 = targets¨\n",
    "    # stepSize is taken as input, range is fixed to 0 --> 2pi. \n",
    "    N = int(np.floor(2 * np.pi/stepSize)) #Number of datapoints\n",
    "    \n",
    "    test = np.zeros((2,N))\n",
    "\n",
    "    for step in range(N):\n",
    "        test[0, step] = step*stepSize+0.05 # Input: will be for example 0.05, 0.15, 0.25 .. 2pi´0.05 etc.. \n",
    "        if (func == 'sin2x'): \n",
    "            test[1, step] = np.sin(2*step*stepSize+0.05) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "        elif (func == 'step2x'): \n",
    "            test[1, step] = np.sign(np.sin(2*step*stepSize+0.05)) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "\n",
    "    return test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBF:\n",
    "    def __init__(self, n = 12, variance = 0.1, maxinput = 6.28):\n",
    "        self.n = n # the number of nodes\n",
    "        self.variance = 0.1 ## Same variance for all nodes\n",
    "        # self.units = np.random.rand(1, n) * maxinput # random unit position in the input space\n",
    "        # self.units = np.array([0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6]) # unit positions \n",
    "        \n",
    "        self.units = np.arange(0, maxinput, maxinput/(n-1))\n",
    "        self.units = np.append(self.units, maxinput)\n",
    "        self.n = self.units.shape[0]\n",
    "        self.w = np.random.rand(1,n)\n",
    "    \n",
    "    def error(self, f_approx, f):\n",
    "        if not (f_approx.shape == f.shape): \n",
    "            raise Exception('f_approx and f shapes mismatch. f_approx: {}, f: {} '.format(f_approx.shape, f.shape))\n",
    "\n",
    "        # error = (phi(x) - target)^2\n",
    "        return np.average(np.abs(f_approx - f))\n",
    "    \n",
    "    def predict(self, inp):\n",
    "        # takes an input inp and returns predictions\n",
    "        # do f^ = phi(x) * w.T\n",
    "        x = inp.dot(np.ones((1, self.n))) # inp x 1 * 1 x n --> inp x n\n",
    "        \n",
    "        # m x n * n x 1 --> m x 1\n",
    "        # print(\"m x n:\")\n",
    "        # print(x.shape)\n",
    "        print(\"n x 1:\")\n",
    "        print(self.w.shape)\n",
    "        f_approx = self.phi_matrix(x).dot(self.w)\n",
    "        # print(\"output shape: \" + str(f_approx.shape))\n",
    "        return f_approx\n",
    "\n",
    "    \n",
    "    def fit(self, inp, f):\n",
    "        # x is the input. Shape: inputs x 1\n",
    "        # f is the true value of the function (aka the target), same shape\n",
    "        if not (inp.shape == f.shape): \n",
    "            raise Exception('inp and f shapes mismatch. inp: {}, f: {} '.format(x.shape, f.shape))\n",
    "        \n",
    "        # print(\"input shape (m x 1):\" + str(inp.shape))\n",
    "        # print(\"target shape (m x 1):\" + str(f.shape))\n",
    "\n",
    "        # We want x to be a matrix with shape: inputs x neurons\n",
    "        x = inp.dot(np.ones((1, self.n))) # inp x 1 * 1 x n --> inp x n\n",
    "        \n",
    "        # print(\"creted x with shape \" + str(x.shape))\n",
    "        \n",
    "        # get phi(x)\n",
    "        self.phi_x = self.phi_matrix(x)\n",
    "        # print(self.phi_x.shape)\n",
    "\n",
    "        # we obtain the w that minimizes the error by solving: \n",
    "        # phi(x).T * phi(x) * w = phi(x).T * f\n",
    "        # --> w = (phi(x).T * phi(x))^-1 * phi(x).T * f\n",
    "        # print(f.shape)\n",
    "        \n",
    "        self.w = np.linalg.inv(self.phi_x.T.dot(self.phi_x)).dot(self.phi_x.T).dot(f)\n",
    "        \n",
    "        print('Model fitted')\n",
    "    \n",
    "    def phi(self, x, i): \n",
    "        return np.exp(-(np.square(x-i))/(2*np.square(self.variance)))\n",
    "    \n",
    "    def phi_matrix(self, x):\n",
    "        # number of inputs (m) (rows) x self.n (n) (columns)\n",
    "        print(\"phi_matrix input size:\" + str(x.shape))\n",
    "        # this is a slow and stupid way of computing phi(x)\n",
    "        for m in range(x.shape[0]): # m\n",
    "            for n in range(x.shape[1]): # n\n",
    "                res = self.phi(x = x[m, n], i = self.units[n])\n",
    "        #        print(\"phi({}, {}): {}\".format(x[row, col], self.units[0, row], res))\n",
    "                x[m, n] = res\n",
    "\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi_matrix input size:(62, 6)\n",
      "Model fitted\n",
      "n x 1:\n",
      "(6, 1)\n",
      "phi_matrix input size:(62, 6)\n",
      "6 units evenly distributed. Res. Err: 0.517\n",
      "phi_matrix input size:(62, 12)\n",
      "Model fitted\n",
      "n x 1:\n",
      "(12, 1)\n",
      "phi_matrix input size:(62, 12)\n",
      "12 units evenly distributed. Res. Err: 0.368\n",
      "phi_matrix input size:(62, 20)\n",
      "Model fitted\n",
      "n x 1:\n",
      "(20, 1)\n",
      "phi_matrix input size:(62, 20)\n",
      "20 units evenly distributed. Res. Err: 0.152\n",
      "phi_matrix input size:(62, 30)\n",
      "Model fitted\n",
      "n x 1:\n",
      "(30, 1)\n",
      "phi_matrix input size:(62, 30)\n",
      "30 units evenly distributed. Res. Err: 0.036\n",
      "phi_matrix input size:(62, 60)\n",
      "Model fitted\n",
      "n x 1:\n",
      "(60, 1)\n",
      "phi_matrix input size:(62, 60)\n",
      "60 units evenly distributed. Res. Err: 0.035\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def test(n):     \n",
    "    model = RBF(n, variance = 0.1)\n",
    "    \n",
    "    function = 'sin2x'\n",
    "    \n",
    "    # Train model\n",
    "    trainset = getTrainSet(function)\n",
    "    # print(function + ' train set example: ')\n",
    "    # print(trainset[0:5, :])\n",
    "    # print(\"Units: \")\n",
    "    # print(model.units)\n",
    "    model.fit(trainset[:, 0][np.newaxis,:].T, trainset[:, 1][np.newaxis,:].T)\n",
    "    \n",
    "    \n",
    "    ## Test Model\n",
    "    \n",
    "    # Get test set\n",
    "    testset = getTestSet(function)\n",
    "    # Make predictions\n",
    "    pred = model.predict(testset[:, 0][np.newaxis,:].T)\n",
    "    # test error\n",
    "    e = model.error(pred, testset[:, 1][np.newaxis,:].T)\n",
    "    # \n",
    "    # print(\"predictions\")\n",
    "    # print(pred[0:5, :])\n",
    "    # print(\"target\")\n",
    "    # print(testset[0:5, :])\n",
    "    # \n",
    "    # print(\"Absolute residual error: {}\".format(e))\n",
    "    # \n",
    "    return e\n",
    "\n",
    "# nvars = np.array([10, 20, 30, 40, 50, 60, 61, 62, 63])\n",
    "# fvars = np.ones(nvars.shape)\n",
    "# for i, n in enumerate(nvars):\n",
    "#     fvars[i] = test(n)\n",
    "#  \n",
    "\n",
    "print(\"{} units evenly distributed. Res. Err: {}\".format(6, round(test(6), 3)))\n",
    "print(\"{} units evenly distributed. Res. Err: {}\".format(12, round(test(12), 3)))\n",
    "print(\"{} units evenly distributed. Res. Err: {}\".format(20, round(test(20), 3)))\n",
    "print(\"{} units evenly distributed. Res. Err: {}\".format(30, round(test(30), 3)))\n",
    "print(\"{} units evenly distributed. Res. Err: {}\".format(60, round(test(60), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Minimizing the residual error\n",
    "\n",
    "With 12 units evenly distributed, variance = 0.1, the Absolute residual error was: 0.32240\n",
    "the error did not change significantly with variance 0.3 or 0.01\n",
    "\n",
    "\n",
    "With 20 units evenly distributed, variance = 0.1, the Absolute residual error was: 0.131492\n",
    "\n",
    "\n",
    "Adding a node in the very end of the interval reduced it somewhat to 0.12314\n",
    "\n",
    "30 units: 0.03243\n",
    "\n",
    "40 units: 0.0313 \n",
    "\n",
    "\n",
    "#### Questions:\n",
    "\n",
    "- What is the lower bound for the number of training examples, N?\n",
    "N must be larger than the number of neurons, n. \n",
    "\n",
    "- What happens with the error if N = n? Why?\n",
    "The error starts increasing. This is because the system is overdetermined. \n",
    "The model can only reach points lying in some fixed plane and can never exactly match y^ if it lies somewhere outside the plane\n",
    "\n",
    "- Under what conditions, if any, does (4) have a solution in this case?\n",
    "Yes, if some equation occurs several times in the system, or if some equations are linear combinations of the others. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
