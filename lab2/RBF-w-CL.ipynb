{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch mode training using least squares - supervised learning of network weights. \n",
    "\n",
    "\n",
    "- Implement a radial basis function network from scratch. \n",
    "\n",
    "- The network will be used to approximate sin(2x) and square(2x) functions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Support functions for the evaluation\n",
    "\n",
    "def getTrainSet(func = 'sin2x', stepSize = 0.1, noise = True):\n",
    "    ## Returns an 2 x N array of a training set\n",
    "    # Row 0 = inputs and row 1 = targets¨\n",
    "    # stepSize is taken as input, range is fixed to 0 --> 2pi. \n",
    "    N = int(np.floor(2 * np.pi/stepSize)) #Number of datapoints\n",
    "    \n",
    "    train = np.zeros((2,N))\n",
    "    inputs = np.arange(0, N)\n",
    "    np.random.shuffle(inputs)\n",
    "    \n",
    "    if (noise):\n",
    "        noise = 1\n",
    "    else: \n",
    "        noise = 0\n",
    "    \n",
    "    for step, i in enumerate(inputs):\n",
    "        train[0, i] = step*stepSize # Input: will be for example 0, 0.1, 0.2 .. 2pi etc.. \n",
    "        if (func == 'sin2x'): \n",
    "            train[1, i] = np.sin(2*step*stepSize) + noise * np.random.normal(0, np.sqrt(0.1)) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "        elif (func == 'step2x'): \n",
    "            train[1, i] = np.sign(np.sin(2*step*stepSize)) + noise * np.random.normal(0, np.sqrt(0.1)) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "\n",
    "    return train.T\n",
    "\n",
    "def getTestSet(func = 'sin2x', stepSize = 0.1):\n",
    "    ## Returns an 2 x N array of a training set\n",
    "    # Row 0 = inputs and row 1 = targets¨\n",
    "    # stepSize is taken as input, range is fixed to 0 --> 2pi. \n",
    "    N = int(np.floor(2 * np.pi/stepSize)) #Number of datapoints\n",
    "    \n",
    "    test = np.zeros((2,N))\n",
    "\n",
    "    for step in range(N):\n",
    "        test[0, step] = step*stepSize+0.05 # Input: will be for example 0.05, 0.15, 0.25 .. 2pi´0.05 etc.. \n",
    "        if (func == 'sin2x'): \n",
    "            test[1, step] = np.sin(2*step*stepSize+0.05) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "        elif (func == 'step2x'): \n",
    "            test[1, step] = np.sign(np.sin(2*step*stepSize+0.05)) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "\n",
    "    return test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBF:\n",
    "    def __init__(self, n = 12, variance = 0.1, learning_rate = 0.1, maxinput = 6.28):\n",
    "        self.n = n # the number of nodes\n",
    "        self.variance = 0.1 ## Same variance for all nodes\n",
    "        # self.units = np.random.rand(1, n) * maxinput # random unit position in the input space\n",
    "        # self.units = np.array([0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6]) # unit positions \n",
    "        \n",
    "        self.units = np.arange(0, maxinput, maxinput/(self.n))\n",
    "        \n",
    "        ## One node in each max and minimum\n",
    "        # self.units = np.arange(0, maxinput, 3.14/2)\n",
    "        # print(\"Units: \")\n",
    "        # print(self.units)\n",
    "        \n",
    "        self.n = self.units.shape[0]\n",
    "        self.w = np.random.rand(1,self.n).T\n",
    "        self.lr = learning_rate\n",
    "\n",
    "    \n",
    "    def error(self, f_approx, f):\n",
    "        # the average error (with direction +/-)\n",
    "        if not (f_approx.shape == f.shape): \n",
    "            raise Exception('f_approx and f shapes mismatch. f_approx: {}, f: {} '.format(f_approx.shape, f.shape))\n",
    "\n",
    "        # error = (phi(x) - target)^2\n",
    "        return np.average(f_approx - f)\n",
    "    \n",
    "    def res_error(self, f_approx, f):\n",
    "        # the residual error (absolute)\n",
    "        if not (f_approx.shape == f.shape): \n",
    "            raise Exception('f_approx and f shapes mismatch. f_approx: {}, f: {} '.format(f_approx.shape, f.shape))\n",
    "\n",
    "        # error = (phi(x) - target)^2\n",
    "        return np.average(np.abs(f_approx - f))            \n",
    "    \n",
    "    def predict(self, inp):\n",
    "        # takes an input inp and returns predictions\n",
    "        # do f^ = phi(x) * w.T\n",
    "        x = inp.dot(np.ones((1, self.n))) # inp x 1 * 1 x n --> inp x n\n",
    "        \n",
    "        # print(\"n x 1:\")\n",
    "        # print(self.w.shape)\n",
    "        \n",
    "        f_approx = self.phi_matrix(x).dot(self.w)\n",
    "        return f_approx\n",
    "    \n",
    "    def fit_lsq(self, inp, f):\n",
    "        # x is the input. Shape: inputs x 1\n",
    "        # f is the true value of the function (aka the target), same shape\n",
    "        if not (inp.shape == f.shape): \n",
    "            raise Exception('inp and f shapes mismatch. inp: {}, f: {} '.format(inp.shape, f.shape))\n",
    "    \n",
    "\n",
    "        # We want x to be a matrix with shape: inputs x neurons\n",
    "        x = inp.dot(np.ones((1, self.n))) # inp x 1 * 1 x n --> inp x n\n",
    "        \n",
    "        \n",
    "        # get phi(x)\n",
    "        self.phi_x = self.phi_matrix(x)\n",
    "\n",
    "        # we obtain the w that minimizes the error by solving: \n",
    "        # phi(x).T * phi(x) * w = phi(x).T * f\n",
    "        # --> w = (phi(x).T * phi(x))^-1 * phi(x).T * f        \n",
    "        self.w = np.linalg.inv(self.phi_x.T.dot(self.phi_x)).dot(self.phi_x.T).dot(f)\n",
    "        \n",
    "    \n",
    "    def fit_delta(self, inp, f):\n",
    "        # x is the input. Shape: inputs x 1\n",
    "        # f is the true value of the function (aka the target), same shape\n",
    "        if not (inp.shape == f.shape): \n",
    "            raise Exception('inp and f shapes mismatch. inp: {}, f: {} '.format(inp.shape, f.shape))\n",
    "        \n",
    "        x = inp.dot(np.ones((1, self.n))) # inp x 1 * 1 x n --> inp x n\n",
    "        \n",
    "        # compute phi(x)\n",
    "        self.phi_x = self.phi_matrix(x)\n",
    "        \n",
    "        # make a prediction\n",
    "        f_approx = self.predict(inp)\n",
    "        \n",
    "        # compute the error\n",
    "        e = self.error(f_approx, f)\n",
    "        \n",
    "        # find delta w\n",
    "        self.dw = -1 * self.lr * e * self.phi_x.T\n",
    "        \n",
    "        #print(\"dw shape\")\n",
    "        #print(dw.shape)\n",
    "\n",
    "        \n",
    "        #update weights\n",
    "        self.w += self.dw\n",
    "            \n",
    "    def cl_vanilla_update(self, sample, learning_rate):\n",
    "        # find the \"winner\" of the units (the one closest to the random sample)\n",
    "        unit_distance = np.abs(self.units - sample)\n",
    "        winner_idx = np.argmin(unit_distance)\n",
    "        \n",
    "        # print(\"CL. Random Sample: {} Winner: {}\".format(sample, self.units[winner_idx]))\n",
    "        \n",
    "        # how far away is the winner's position from the sample? \n",
    "        dp = -1 * learning_rate * (self.units[winner_idx] - sample)\n",
    "        \n",
    "        # update the winner's position to be slightly closer to the random sample\n",
    "        self.units[winner_idx] += dp\n",
    "\n",
    "    def cl_multi_update(self, sample, learning_rate, winners = 5):\n",
    "        # by looking for multiple winners, we avoid dead units. \n",
    "        \n",
    "        # find multiple \"winners\" of the units (the one closest to the random sample)\n",
    "        unit_distance = np.abs(self.units - sample)\n",
    "        \n",
    "        for i in range(winners):\n",
    "            winner_idx = np.argmin(unit_distance)\n",
    "            unit_distance[winner_idx] = np.inf # set this distance to inf so its not selected again     \n",
    "            \n",
    "            # how far away is the winner's position from the sample? \n",
    "            dp = -1 * learning_rate * (self.units[winner_idx] - sample)\n",
    "            \n",
    "            # Checked w. this print, seems to work\n",
    "            # print(\"CL. Random Sample: {} Winner: {}. Diff: {}. Moving {} to: {}\".format(sample, self.units[winner_idx], dp, winner_idx, self.units[winner_idx]+dp))\n",
    "\n",
    "            # update the winner's position to be slightly closer to the random sample\n",
    "            self.units[winner_idx] += dp\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "    def phi(self, x, i): \n",
    "        return np.exp(-(np.square(x-i))/(2*np.square(self.variance)))\n",
    "    \n",
    "    \n",
    "    def phi_matrix(self, x):\n",
    "        # number of inputs (m) (rows) x self.n (n) (columns)\n",
    "        # print(\"phi_matrix input size:\" + str(x.shape))\n",
    "        # this is a slow and stupid way of computing phi(x)\n",
    "        for m in range(x.shape[0]): # m\n",
    "            for n in range(x.shape[1]): # n\n",
    "                res = self.phi(x = x[m, n], i = self.units[n])\n",
    "        #        print(\"phi({}, {}): {}\".format(x[row, col], self.units[0, row], res))\n",
    "                x[m, n] = res\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function = 'sin2x'\n",
    "\n",
    "# Train model\n",
    "trainset = getTrainSet(function, noise = True)\n",
    "\n",
    "## Test Model\n",
    "# Get test set\n",
    "testset = getTestSet(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy data. No CL: 0.19\n",
      "Noisy data. Vanilla CL: 0.199\n",
      "Noisy data. Multi CL: 0.2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAEoCAYAAABihUTEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wOotm9TF0bhPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ee84c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def batch(n, trainset, testset, variance = 0.1):\n",
    "    model = RBF(n, variance = 0.1)\n",
    "    \n",
    "    # fit model\n",
    "    model.fit_lsq(trainset[:, 0][np.newaxis,:].T, trainset[:, 1][np.newaxis,:].T)\n",
    "    \n",
    "    ## Test Model\n",
    "    # Make predictions\n",
    "    pred = model.predict(testset[:, 0][np.newaxis,:].T)\n",
    "    # test error\n",
    "    e = model.res_error(pred, testset[:, 1][np.newaxis,:].T)\n",
    "\n",
    "    print(\"Absolute residual error: {}\".format(e))\n",
    "\n",
    "\n",
    "def delta(n, trainset, testset, variance = 0.1, learning_rate = 0.1, epochs = 20, cl = 'none'):\n",
    "    model = RBF(n, variance, learning_rate, maxinput = 6.28)\n",
    "    #fit model\n",
    "    # for epoch in range(epochs): \n",
    "    previous_error = np.inf\n",
    "    e = np.inf\n",
    "    epoch = 0\n",
    "    while e <= previous_error: # while test error decreases\n",
    "        np.random.shuffle(trainset)\n",
    "        for tupl in trainset:\n",
    "            sample = np.array([tupl[0]])[np.newaxis,:].T\n",
    "            target = np.array([tupl[1]])[np.newaxis,:].T\n",
    "            model.fit_delta(sample, target)\n",
    "        \n",
    "        if (cl == 'vanilla'): \n",
    "            # Update units through competetive learning\n",
    "            rand = np.random.choice(trainset[:, 0])\n",
    "            model.cl_vanilla_update(rand, 0.2)\n",
    "        elif (cl == 'multi'): \n",
    "            # Update units through competetive learning\n",
    "            rand = np.random.choice(trainset[:, 0])\n",
    "            model.cl_multi_update(rand, 0.2, 6)\n",
    "        \n",
    "        # Make predictions\n",
    "        pred = model.predict(testset[:, 0][np.newaxis,:].T)\n",
    "        # test error\n",
    "        previous_error = e\n",
    "        e = model.res_error(pred, testset[:, 1][np.newaxis,:].T)\n",
    "        epoch += 1\n",
    "   #     if (epoch % 5 == 0):\n",
    "   #         print(\"Epoch {}, residual error: {}, dw: {}\".format(epoch, e, np.average(model.dw)))\n",
    "   # print(\"Epoch {}, residual error: {}, dw: {} \".format(epoch, e, np.average(model.dw)))\n",
    "\n",
    "    return model, e\n",
    "    \n",
    "\n",
    "\n",
    "units = 30\n",
    "width = 0.1\n",
    "lr = 0.7\n",
    "epochs = 1000\n",
    "# batch(units, trainset, testset, width)\n",
    "mod1, noise_nocl = delta(units, trainset, testset, width, lr, epochs)\n",
    "mod2, noise_cl_van = delta(units, trainset, testset, width, lr, epochs, cl = 'vanilla')\n",
    "mod3, noise_cl_mul = delta(units, trainset, testset, width, lr, epochs, cl = 'multi')\n",
    "print(\"Noisy data. No CL: {}\".format(round(noise_nocl, 3)))\n",
    "print(\"Noisy data. Vanilla CL: {}\".format(round(noise_cl_van, 3)))\n",
    "print(\"Noisy data. Multi CL: {}\".format(round(noise_cl_mul, 3)))\n",
    "\n",
    "## Compare units\n",
    "## Scatter Plot\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (10, 10))\n",
    "ax = fig.add_subplot(211)\n",
    "# ax.scatter(mod1.units, np.ones(mod1.units.shape), marker = \"o\", c = 'green')\n",
    "ax.scatter(mod3.units, np.ones(mod1.units.shape), marker = \"o\", c = 'blue', label = 'Multiple CL')\n",
    "ax.scatter(mod1.units, np.ones(mod1.units.shape), marker = \"o\", c = 'red', label = 'No CL')\n",
    "ax.set(title='',\n",
    "        xlabel = \"Unit pos\",\n",
    "      ylim = (0, 2))\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy data. No CL: 0.4415473107039592\n",
      "Noisy data. With CL: 0.23859607373295577\n",
      "Noisy data. No CL: 0.04462424426494158\n",
      "Noisy data. CL: 0.04829242257684326\n"
     ]
    }
   ],
   "source": [
    "print(\"Noisy data. No CL: {}\".format(noisy_nocl))\n",
    "print(\"Noisy data. With CL: {}\".format(noisy_cl))\n",
    "print(\"Noisy data. No CL: {}\".format(clean_nocl))\n",
    "print(\"Noisy data. CL: {}\".format(clean_cl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Minimizing the residual error\n",
    "\n",
    "With 12 units evenly distributed, variance = 0.1, the Absolute residual error was: 0.32240\n",
    "the error did not change significantly with variance 0.3 or 0.01\n",
    "\n",
    "\n",
    "With 20 units evenly distributed, variance = 0.1, the Absolute residual error was: 0.131492\n",
    "\n",
    "\n",
    "Adding a node in the very end of the interval reduced it somewhat to 0.12314\n",
    "\n",
    "30 units: 0.03243\n",
    "\n",
    "40 units: 0.0313 \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.57090909,  1.14181818,  1.71272727,  2.28363636,\n",
       "        2.85454545,  3.42545455,  3.99636364,  4.56727273,  5.13818182,\n",
       "        5.70909091])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 6.28, 6.28/11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94593827,  0.50419356,  0.57720877,  0.45551226,  0.42067183]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05406173, -0.49580644, -0.42279123, -0.54448774, -0.57932817]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
