{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch mode training using least squares - supervised learning of network weights. \n",
    "\n",
    "\n",
    "- Implement a radial basis function network from scratch. \n",
    "\n",
    "- The network will be used to approximate sin(2x) and square(2x) functions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Support functions for the evaluation\n",
    "\n",
    "def getTrainSet(func = 'sin2x', stepSize = 0.1, noise = True):\n",
    "    ## Returns an 2 x N array of a training set\n",
    "    # Row 0 = inputs and row 1 = targets¨\n",
    "    # stepSize is taken as input, range is fixed to 0 --> 2pi. \n",
    "    N = int(np.floor(2 * np.pi/stepSize)) #Number of datapoints\n",
    "    \n",
    "    train = np.zeros((2,N))\n",
    "    inputs = np.arange(0, N)\n",
    "    np.random.shuffle(inputs)\n",
    "    \n",
    "    if (noise):\n",
    "        noise = 1\n",
    "    else: \n",
    "        noise = 0\n",
    "    \n",
    "    for step, i in enumerate(inputs):\n",
    "        train[0, i] = step*stepSize # Input: will be for example 0, 0.1, 0.2 .. 2pi etc.. \n",
    "        if (func == 'sin2x'): \n",
    "            train[1, i] = np.sin(2*step*stepSize) + noise * np.random.normal(0, np.sqrt(0.1)) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "        elif (func == 'step2x'): \n",
    "            train[1, i] = np.sign(np.sin(2*step*stepSize)) + noise * np.random.normal(0, np.sqrt(0.1)) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "\n",
    "    return train.T\n",
    "\n",
    "def getTestSet(func = 'sin2x', stepSize = 0.1):\n",
    "    ## Returns an 2 x N array of a training set\n",
    "    # Row 0 = inputs and row 1 = targets¨\n",
    "    # stepSize is taken as input, range is fixed to 0 --> 2pi. \n",
    "    N = int(np.floor(2 * np.pi/stepSize)) #Number of datapoints\n",
    "    \n",
    "    test = np.zeros((2,N))\n",
    "\n",
    "    for step in range(N):\n",
    "        test[0, step] = step*stepSize+0.05 # Input: will be for example 0.05, 0.15, 0.25 .. 2pi´0.05 etc.. \n",
    "        if (func == 'sin2x'): \n",
    "            test[1, step] = np.sin(2*step*stepSize+0.05) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "        elif (func == 'step2x'): \n",
    "            test[1, step] = np.sign(np.sin(2*step*stepSize+0.05)) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "\n",
    "    return test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBF:\n",
    "    def __init__(self, n = 12, variance = 0.1, learning_rate = 0.1, maxinput = 6.28):\n",
    "        self.n = n # the number of nodes\n",
    "        self.variance = 0.1 ## Same variance for all nodes\n",
    "        # self.units = np.random.rand(1, n) * maxinput # random unit position in the input space\n",
    "        # self.units = np.array([0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6]) # unit positions \n",
    "        \n",
    "        self.units = np.arange(0, maxinput, maxinput/(self.n))\n",
    "        \n",
    "        ## One node in each max and minimum\n",
    "        # self.units = np.arange(0, maxinput, 3.14/2)\n",
    "        # print(\"Units: \")\n",
    "        # print(self.units)\n",
    "        \n",
    "        self.n = self.units.shape[0]\n",
    "        self.w = np.random.rand(1,self.n).T\n",
    "        self.lr = learning_rate\n",
    "        #print(\"Initiated weights, shape: \")\n",
    "        #print(self.w.shape)\n",
    "        #\n",
    "        print(\"Initiated units: \")\n",
    "        print(self.units)\n",
    "        print(self.n)\n",
    "    \n",
    "    def error(self, f_approx, f):\n",
    "        # the average error (with direction +/-)\n",
    "        if not (f_approx.shape == f.shape): \n",
    "            raise Exception('f_approx and f shapes mismatch. f_approx: {}, f: {} '.format(f_approx.shape, f.shape))\n",
    "\n",
    "        # error = (phi(x) - target)^2\n",
    "        return np.average(f_approx - f)\n",
    "    \n",
    "    def res_error(self, f_approx, f):\n",
    "        # the residual error (absolute)\n",
    "        if not (f_approx.shape == f.shape): \n",
    "            raise Exception('f_approx and f shapes mismatch. f_approx: {}, f: {} '.format(f_approx.shape, f.shape))\n",
    "\n",
    "        # error = (phi(x) - target)^2\n",
    "        return np.average(np.abs(f_approx - f))            \n",
    "    \n",
    "    def predict(self, inp):\n",
    "        # takes an input inp and returns predictions\n",
    "        # do f^ = phi(x) * w.T\n",
    "        x = inp.dot(np.ones((1, self.n))) # inp x 1 * 1 x n --> inp x n\n",
    "        \n",
    "        # print(\"n x 1:\")\n",
    "        # print(self.w.shape)\n",
    "        \n",
    "        f_approx = self.phi_matrix(x).dot(self.w)\n",
    "        return f_approx\n",
    "    \n",
    "    def fit_lsq(self, inp, f):\n",
    "        # x is the input. Shape: inputs x 1\n",
    "        # f is the true value of the function (aka the target), same shape\n",
    "        if not (inp.shape == f.shape): \n",
    "            raise Exception('inp and f shapes mismatch. inp: {}, f: {} '.format(inp.shape, f.shape))\n",
    "    \n",
    "\n",
    "        # We want x to be a matrix with shape: inputs x neurons\n",
    "        x = inp.dot(np.ones((1, self.n))) # inp x 1 * 1 x n --> inp x n\n",
    "        \n",
    "        \n",
    "        # get phi(x)\n",
    "        self.phi_x = self.phi_matrix(x)\n",
    "\n",
    "        # we obtain the w that minimizes the error by solving: \n",
    "        # phi(x).T * phi(x) * w = phi(x).T * f\n",
    "        # --> w = (phi(x).T * phi(x))^-1 * phi(x).T * f        \n",
    "        self.w = np.linalg.inv(self.phi_x.T.dot(self.phi_x)).dot(self.phi_x.T).dot(f)\n",
    "        \n",
    "    \n",
    "    def fit_delta(self, inp, f):\n",
    "        # x is the input. Shape: inputs x 1\n",
    "        # f is the true value of the function (aka the target), same shape\n",
    "        if not (inp.shape == f.shape): \n",
    "            raise Exception('inp and f shapes mismatch. inp: {}, f: {} '.format(inp.shape, f.shape))\n",
    "        \n",
    "        x = inp.dot(np.ones((1, self.n))) # inp x 1 * 1 x n --> inp x n\n",
    "        \n",
    "        # compute phi(x)\n",
    "        self.phi_x = self.phi_matrix(x)\n",
    "        \n",
    "        # make a prediction\n",
    "        f_approx = self.predict(inp)\n",
    "        \n",
    "        # compute the error\n",
    "        e = self.error(f_approx, f)\n",
    "        \n",
    "        # find delta w\n",
    "        self.dw = -1 * self.lr * e * self.phi_x.T\n",
    "        \n",
    "        #print(\"dw shape\")\n",
    "        #print(dw.shape)\n",
    "\n",
    "        \n",
    "        #update weights\n",
    "        self.w += self.dw\n",
    "            \n",
    "    def cl_vanilla_update(self, sample, learning_rate):\n",
    "        # find the \"winner\" of the units (the one closest to the random sample)\n",
    "        unit_distance = np.abs(self.units - sample)\n",
    "        winner_idx = np.argmin(unit_distance)\n",
    "        \n",
    "        # print(\"CL. Random Sample: {} Winner: {}\".format(sample, self.units[winner_idx]))\n",
    "        \n",
    "        # how far away is the winner's position from the sample? \n",
    "        dp = -1 * learning_rate * (self.units[winner_idx] - sample)\n",
    "        \n",
    "        # update the winner's position to be slightly closer to the random sample\n",
    "        self.units[winner_idx] += dp\n",
    "\n",
    "    def cl_multi_update(self, sample, learning_rate, winners = 5):\n",
    "        # by looking for multiple winners, we avoid dead units. \n",
    "        \n",
    "        # find multiple \"winners\" of the units (the one closest to the random sample)\n",
    "        unit_distance = np.abs(self.units - sample)\n",
    "        \n",
    "        for i in range(winners):\n",
    "            winner_idx = np.argmin(unit_distance)\n",
    "            unit_distance[winner_idx] = np.inf # set this distance to inf so its not selected again     \n",
    "            \n",
    "            # how far away is the winner's position from the sample? \n",
    "            dp = -1 * learning_rate * (self.units[winner_idx] - sample)\n",
    "            \n",
    "            # Checked w. this print, seems to work\n",
    "            # print(\"CL. Random Sample: {} Winner: {}. Diff: {}. Moving {} to: {}\".format(sample, self.units[winner_idx], dp, winner_idx, self.units[winner_idx]+dp))\n",
    "\n",
    "            # update the winner's position to be slightly closer to the random sample\n",
    "            self.units[winner_idx] += dp\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "    def phi(self, x, i): \n",
    "        return np.exp(-(np.square(x-i))/(2*np.square(self.variance)))\n",
    "    \n",
    "    \n",
    "    def phi_matrix(self, x):\n",
    "        # number of inputs (m) (rows) x self.n (n) (columns)\n",
    "        # print(\"phi_matrix input size:\" + str(x.shape))\n",
    "        # this is a slow and stupid way of computing phi(x)\n",
    "        for m in range(x.shape[0]): # m\n",
    "            for n in range(x.shape[1]): # n\n",
    "                res = self.phi(x = x[m, n], i = self.units[n])\n",
    "        #        print(\"phi({}, {}): {}\".format(x[row, col], self.units[0, row], res))\n",
    "                x[m, n] = res\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function = 'sin2x'\n",
    "\n",
    "# Train model\n",
    "trainset = getTrainSet(function, noise = True)\n",
    "\n",
    "## Test Model\n",
    "# Get test set\n",
    "testset = getTestSet(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiated units: \n",
      "[ 0.          0.20933333  0.41866667  0.628       0.83733333  1.04666667\n",
      "  1.256       1.46533333  1.67466667  1.884       2.09333333  2.30266667\n",
      "  2.512       2.72133333  2.93066667  3.14        3.34933333  3.55866667\n",
      "  3.768       3.97733333  4.18666667  4.396       4.60533333  4.81466667\n",
      "  5.024       5.23333333  5.44266667  5.652       5.86133333  6.07066667]\n",
      "30\n",
      "Epoch 5, residual error: 0.14988047192023776, dw: -0.00017853479819043003\n",
      "Epoch 5, residual error: 0.14988047192023776, dw: -0.00017853479819043003 \n",
      "[ 0.          0.20933333  0.41866667  0.628       0.83733333  1.04666667\n",
      "  1.256       1.46533333  1.67466667  1.884       2.09333333  2.30266667\n",
      "  2.512       2.72133333  2.93066667  3.14        3.34933333  3.55866667\n",
      "  3.768       3.97733333  4.18666667  4.396       4.60533333  4.81466667\n",
      "  5.024       5.23333333  5.44266667  5.652       5.86133333  6.07066667]\n",
      "Initiated units: \n",
      "[ 0.          0.20933333  0.41866667  0.628       0.83733333  1.04666667\n",
      "  1.256       1.46533333  1.67466667  1.884       2.09333333  2.30266667\n",
      "  2.512       2.72133333  2.93066667  3.14        3.34933333  3.55866667\n",
      "  3.768       3.97733333  4.18666667  4.396       4.60533333  4.81466667\n",
      "  5.024       5.23333333  5.44266667  5.652       5.86133333  6.07066667]\n",
      "30\n",
      "Epoch 5, residual error: 0.16094824973666105, dw: 0.0016250705825456542\n",
      "Epoch 5, residual error: 0.16094824973666105, dw: 0.0016250705825456542 \n",
      "[ 0.          0.20933333  0.41866667  0.6352      0.83733333  1.04666667\n",
      "  1.256       1.4688      1.67466667  1.884       2.09333333  2.30266667\n",
      "  2.5208      2.72133333  2.9276      3.14        3.34933333  3.55866667\n",
      "  3.768       3.97733333  4.18666667  4.396       4.60533333  4.81466667\n",
      "  5.024       5.23333333  5.44266667  5.6568      5.86133333  6.07066667]\n",
      "Initiated units: \n",
      "[ 0.          0.20933333  0.41866667  0.628       0.83733333  1.04666667\n",
      "  1.256       1.46533333  1.67466667  1.884       2.09333333  2.30266667\n",
      "  2.512       2.72133333  2.93066667  3.14        3.34933333  3.55866667\n",
      "  3.768       3.97733333  4.18666667  4.396       4.60533333  4.81466667\n",
      "  5.024       5.23333333  5.44266667  5.652       5.86133333  6.07066667]\n",
      "30\n",
      "Epoch 5, residual error: 0.1587920524589984, dw: 0.0018574737256067738\n",
      "Epoch 5, residual error: 0.1587920524589984, dw: 0.0018574737256067738 \n",
      "[ 0.          0.20933333  0.41866667  0.6352      0.8236      1.04666667\n",
      "  1.256       1.46533333  1.67466667  1.884       2.09333333  2.30266667\n",
      "  2.512       2.72133333  2.93066667  3.14        3.34933333  3.55866667\n",
      "  3.768       3.97733333  4.188       4.3764      4.60533333  4.81466667\n",
      "  5.024       5.246       5.41556     5.652       5.8652      6.0536    ]\n",
      "Noisy data. No CL: 0.14988047192023776\n",
      "Noisy data. Vanilla CL: 0.16094824973666105\n",
      "Noisy data. Multi CL: 0.1587920524589984\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAACUCAYAAABoZ2lmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f017cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def batch(n, trainset, testset, variance = 0.1):\n",
    "    model = RBF(n, variance = 0.1)\n",
    "    \n",
    "    # fit model\n",
    "    model.fit_lsq(trainset[:, 0][np.newaxis,:].T, trainset[:, 1][np.newaxis,:].T)\n",
    "    \n",
    "    ## Test Model\n",
    "    # Make predictions\n",
    "    pred = model.predict(testset[:, 0][np.newaxis,:].T)\n",
    "    # test error\n",
    "    e = model.res_error(pred, testset[:, 1][np.newaxis,:].T)\n",
    "\n",
    "    print(\"Absolute residual error: {}\".format(e))\n",
    "\n",
    "\n",
    "def delta(n, trainset, testset, variance = 0.1, learning_rate = 0.1, epochs = 20, cl = 'none'):\n",
    "    model = RBF(n, variance, learning_rate, maxinput = 6.28)\n",
    "    #fit model\n",
    "    # for epoch in range(epochs): \n",
    "    previous_error = np.inf\n",
    "    e = np.inf\n",
    "    epoch = 0\n",
    "    while e <= previous_error: # while test error decreases\n",
    "        np.random.shuffle(trainset)\n",
    "        for tupl in trainset:\n",
    "            sample = np.array([tupl[0]])[np.newaxis,:].T\n",
    "            target = np.array([tupl[1]])[np.newaxis,:].T\n",
    "            model.fit_delta(sample, target)\n",
    "        \n",
    "        if (cl == 'vanilla'): \n",
    "            # Update units through competetive learning\n",
    "            rand = np.random.choice(trainset[:, 0])\n",
    "            model.cl_vanilla_update(rand, 0.1)\n",
    "        elif (cl == 'multi'): \n",
    "            # Update units through competetive learning\n",
    "            rand = np.random.choice(trainset[:, 0])\n",
    "            model.cl_multi_update(rand, 0.1, 2)\n",
    "        \n",
    "        # Make predictions\n",
    "        pred = model.predict(testset[:, 0][np.newaxis,:].T)\n",
    "        # test error\n",
    "        previous_error = e\n",
    "        e = model.res_error(pred, testset[:, 1][np.newaxis,:].T)\n",
    "        epoch += 1\n",
    "        if (epoch % 5 == 0):\n",
    "            print(\"Epoch {}, residual error: {}, dw: {}\".format(epoch, e, np.average(model.dw)))\n",
    "    print(\"Epoch {}, residual error: {}, dw: {} \".format(epoch, e, np.average(model.dw)))\n",
    "\n",
    "    print(model.units)\n",
    "    return model, e\n",
    "    \n",
    "\n",
    "\n",
    "units = 30\n",
    "width = 0.1\n",
    "lr = 0.25\n",
    "epochs = 100\n",
    "# batch(units, trainset, testset, width)\n",
    "mod1, noise_nocl = delta(units, trainset, testset, width, lr, epochs)\n",
    "mod2, noise_cl_van = delta(units, trainset, testset, width, lr, epochs, cl = 'vanilla')\n",
    "mod3, noise_cl_mul = delta(units, trainset, testset, width, lr, epochs, cl = 'multi')\n",
    "print(\"Noisy data. No CL: {}\".format(noise_nocl))\n",
    "print(\"Noisy data. Vanilla CL: {}\".format(noise_cl_van))\n",
    "print(\"Noisy data. Multi CL: {}\".format(noise_cl_mul))\n",
    "\n",
    "## Compare units\n",
    "## Scatter Plot\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(211)\n",
    "# ax.scatter(mod1.units, np.ones(mod1.units.shape), marker = \"o\", c = 'green')\n",
    "ax.scatter(mod2.units, np.ones(mod1.units.shape), marker = \"o\", c = 'red')\n",
    "ax.scatter(mod3.units, np.ones(mod1.units.shape), marker = \"o\", c = 'blue')\n",
    "ax.set(title='',\n",
    "        xlabel = \"Unit pos\",\n",
    "      ylim = (0, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy data. No CL: 0.4415473107039592\n",
      "Noisy data. With CL: 0.23859607373295577\n",
      "Noisy data. No CL: 0.04462424426494158\n",
      "Noisy data. CL: 0.04829242257684326\n"
     ]
    }
   ],
   "source": [
    "print(\"Noisy data. No CL: {}\".format(noisy_nocl))\n",
    "print(\"Noisy data. With CL: {}\".format(noisy_cl))\n",
    "print(\"Noisy data. No CL: {}\".format(clean_nocl))\n",
    "print(\"Noisy data. CL: {}\".format(clean_cl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Minimizing the residual error\n",
    "\n",
    "With 12 units evenly distributed, variance = 0.1, the Absolute residual error was: 0.32240\n",
    "the error did not change significantly with variance 0.3 or 0.01\n",
    "\n",
    "\n",
    "With 20 units evenly distributed, variance = 0.1, the Absolute residual error was: 0.131492\n",
    "\n",
    "\n",
    "Adding a node in the very end of the interval reduced it somewhat to 0.12314\n",
    "\n",
    "30 units: 0.03243\n",
    "\n",
    "40 units: 0.0313 \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.57090909,  1.14181818,  1.71272727,  2.28363636,\n",
       "        2.85454545,  3.42545455,  3.99636364,  4.56727273,  5.13818182,\n",
       "        5.70909091])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 6.28, 6.28/11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94593827,  0.50419356,  0.57720877,  0.45551226,  0.42067183]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05406173, -0.49580644, -0.42279123, -0.54448774, -0.57932817]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
