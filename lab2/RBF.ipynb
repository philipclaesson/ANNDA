{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch mode training using least squares - supervised learning of network weights. \n",
    "\n",
    "\n",
    "- Implement a radial basis function network from scratch. \n",
    "\n",
    "- The network will be used to approximate sin(2x) and square(2x) functions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Support functions for the evaluation\n",
    "\n",
    "def getTrainSet(func = 'sin2x', stepSize = 0.1):\n",
    "    ## Returns an 2 x N array of a training set\n",
    "    # Row 0 = inputs and row 1 = targets¨\n",
    "    # stepSize is taken as input, range is fixed to 0 --> 2pi. \n",
    "    N = int(np.floor(2 * np.pi/stepSize)) #Number of datapoints\n",
    "    \n",
    "    train = np.zeros((2,N))\n",
    "    inputs = np.arange(0, N)\n",
    "    np.random.shuffle(inputs)\n",
    "    \n",
    "    for step, i in enumerate(inputs):\n",
    "        train[0, i] = step*stepSize # Input: will be for example 0, 0.1, 0.2 .. 2pi etc.. \n",
    "        if (func == 'sin2x'): \n",
    "            train[1, i] = np.sin(2*step*stepSize) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "        elif (func == 'step2x'): \n",
    "            train[1, i] = np.sign(np.sin(2*step*stepSize)) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "\n",
    "    return train.T\n",
    "\n",
    "def getTestSet(func = 'sin2x', stepSize = 0.1):\n",
    "    ## Returns an 2 x N array of a training set\n",
    "    # Row 0 = inputs and row 1 = targets¨\n",
    "    # stepSize is taken as input, range is fixed to 0 --> 2pi. \n",
    "    N = int(np.floor(2 * np.pi/stepSize)) #Number of datapoints\n",
    "    \n",
    "    test = np.zeros((2,N))\n",
    "\n",
    "    for step in range(N):\n",
    "        test[0, step] = step*stepSize+0.05 # Input: will be for example 0.05, 0.15, 0.25 .. 2pi´0.05 etc.. \n",
    "        if (func == 'sin2x'): \n",
    "            test[1, step] = np.sin(2*step*stepSize+0.05) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "        elif (func == 'step2x'): \n",
    "            test[1, step] = np.sign(np.sin(2*step*stepSize+0.05)) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "\n",
    "    return test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBF:\n",
    "    def __init__(self, n = 12, variance = 0.1, maxinput = 6.28):\n",
    "        self.n = n # the number of nodes\n",
    "        self.variance = 0.1 ## Same variance for all nodes\n",
    "        # self.units = np.random.rand(1, n) * maxinput # random unit position in the input space\n",
    "        # self.units = np.array([0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6]) # unit positions \n",
    "        \n",
    "        self.units = np.arange(0, maxinput, maxinput/(n-1))\n",
    "        self.units = np.append(self.units, maxinput)\n",
    "        self.n = self.units.shape[0]\n",
    "        self.w = np.random.rand(1,n)\n",
    "    \n",
    "    def error(self, f_approx, f):\n",
    "        if not (f_approx.shape == f.shape): \n",
    "            raise Exception('f_approx and f shapes mismatch. f_approx: {}, f: {} '.format(f_approx.shape, f.shape))\n",
    "\n",
    "        # error = (phi(x) - target)^2\n",
    "        return np.average(np.abs(f_approx - f))\n",
    "    \n",
    "    def predict(self, inp):\n",
    "        # takes an input inp and returns predictions\n",
    "        # do f^ = phi(x) * w.T\n",
    "        x = inp.dot(np.ones((1, self.n))) # inp x 1 * 1 x n --> inp x n\n",
    "        \n",
    "        # m x n * n x 1 --> m x 1\n",
    "        # print(\"m x n:\")\n",
    "        # print(x.shape)\n",
    "        print(\"n x 1:\")\n",
    "        print(self.w.shape)\n",
    "        f_approx = self.phi_matrix(x).dot(self.w)\n",
    "        # print(\"output shape: \" + str(f_approx.shape))\n",
    "        return f_approx\n",
    "\n",
    "    \n",
    "    def fit(self, inp, f):\n",
    "        # x is the input. Shape: inputs x 1\n",
    "        # f is the true value of the function (aka the target), same shape\n",
    "        if not (inp.shape == f.shape): \n",
    "            raise Exception('inp and f shapes mismatch. inp: {}, f: {} '.format(x.shape, f.shape))\n",
    "        \n",
    "        # print(\"input shape (m x 1):\" + str(inp.shape))\n",
    "        # print(\"target shape (m x 1):\" + str(f.shape))\n",
    "\n",
    "        # We want x to be a matrix with shape: inputs x neurons\n",
    "        x = inp.dot(np.ones((1, self.n))) # inp x 1 * 1 x n --> inp x n\n",
    "        \n",
    "        # print(\"creted x with shape \" + str(x.shape))\n",
    "        \n",
    "        # get phi(x)\n",
    "        self.phi_x = self.phi_matrix(x)\n",
    "        # print(self.phi_x.shape)\n",
    "\n",
    "        # we obtain the w that minimizes the error by solving: \n",
    "        # phi(x).T * phi(x) * w = phi(x).T * f\n",
    "        # --> w = (phi(x).T * phi(x))^-1 * phi(x).T * f\n",
    "        # print(f.shape)\n",
    "        \n",
    "        self.w = np.linalg.inv(self.phi_x.T.dot(self.phi_x)).dot(self.phi_x.T).dot(f)\n",
    "        \n",
    "        print('Model fitted')\n",
    "    \n",
    "    def phi(self, x, i): \n",
    "        return np.exp(-(np.square(x-i))/(2*np.square(self.variance)))\n",
    "    \n",
    "    def phi_matrix(self, x):\n",
    "        # number of inputs (m) (rows) x self.n (n) (columns)\n",
    "        print(\"phi_matrix input size:\" + str(x.shape))\n",
    "        # this is a slow and stupid way of computing phi(x)\n",
    "        for m in range(x.shape[0]): # m\n",
    "            for n in range(x.shape[1]): # n\n",
    "                res = self.phi(x = x[m, n], i = self.units[n])\n",
    "        #        print(\"phi({}, {}): {}\".format(x[row, col], self.units[0, row], res))\n",
    "                x[m, n] = res\n",
    "\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi_matrix input size:(62, 10)\n",
      "Model fitted\n",
      "n x 1:\n",
      "(10, 1)\n",
      "phi_matrix input size:(62, 10)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nvars' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e629137614a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m211\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"o\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m ax.set(title='',\n\u001b[1;32m     48\u001b[0m         \u001b[0mxlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"neurons\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nvars' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def test(n):     \n",
    "    model = RBF(n, variance = 0.1)\n",
    "    \n",
    "    function = 'sin2x'\n",
    "    \n",
    "    # Train model\n",
    "    trainset = getTrainSet(function)\n",
    "    # print(function + ' train set example: ')\n",
    "    # print(trainset[0:5, :])\n",
    "    # print(\"Units: \")\n",
    "    # print(model.units)\n",
    "    model.fit(trainset[:, 0][np.newaxis,:].T, trainset[:, 1][np.newaxis,:].T)\n",
    "    \n",
    "    \n",
    "    ## Test Model\n",
    "    \n",
    "    # Get test set\n",
    "    testset = getTestSet(function)\n",
    "    # Make predictions\n",
    "    pred = model.predict(testset[:, 0][np.newaxis,:].T)\n",
    "    # test error\n",
    "    e = model.error(pred, testset[:, 1][np.newaxis,:].T)\n",
    "    # \n",
    "    # print(\"predictions\")\n",
    "    # print(pred[0:5, :])\n",
    "    # print(\"target\")\n",
    "    # print(testset[0:5, :])\n",
    "    # \n",
    "    # print(\"Absolute residual error: {}\".format(e))\n",
    "    # \n",
    "    return e\n",
    "\n",
    "# nvars = np.array([10, 20, 30, 40, 50, 60, 61, 62, 63])\n",
    "# fvars = np.ones(nvars.shape)\n",
    "# for i, n in enumerate(nvars):\n",
    "#     fvars[i] = test(n)\n",
    "#  \n",
    "\n",
    "test(10)\n",
    "\n",
    "\n",
    "## Scatter Plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(211)\n",
    "ax.scatter(nvars, fvars, marker = \"o\")\n",
    "ax.set(title='',\n",
    "        xlabel = \"neurons\",\n",
    "        ylabel=\"residual error\",\n",
    "      ylim = (0, 0.7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi_matrix input size:(62, 60)\n",
      "Model fitted\n",
      "phi_matrix input size:(62, 60)\n",
      "phi_matrix input size:(62, 100)\n",
      "Model fitted\n",
      "phi_matrix input size:(62, 100)\n",
      "6.68954069422e+13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+000,   0.00000000e+000,   1.16947281e-310, ...,\n",
       "          1.09988986e-075,   3.05628512e-089,   6.35250785e-104],\n",
       "       [  0.00000000e+000,   0.00000000e+000,   0.00000000e+000, ...,\n",
       "          1.65101631e-003,   1.41735335e-006,   9.10147076e-011],\n",
       "       [  0.00000000e+000,   0.00000000e+000,   0.00000000e+000, ...,\n",
       "          9.15380442e-001,   4.92754153e-001,   1.98410947e-002],\n",
       "       ..., \n",
       "       [  0.00000000e+000,   0.00000000e+000,   0.00000000e+000, ...,\n",
       "          8.45436095e-001,   9.09460783e-002,   7.31802419e-004],\n",
       "       [  8.37894253e-126,   1.39300896e-109,   1.73230869e-094, ...,\n",
       "          1.29815834e-275,   4.66271947e-301,   0.00000000e+000],\n",
       "       [  1.26641655e-014,   1.36186389e-009,   1.09546246e-005, ...,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(60)\n",
    "model.phi_x\n",
    "\n",
    "\n",
    "print(test(100))\n",
    "model.phi_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Minimizing the residual error\n",
    "\n",
    "With 12 units evenly distributed, variance = 0.1, the Absolute residual error was: 0.32240\n",
    "the error did not change significantly with variance 0.3 or 0.01\n",
    "\n",
    "\n",
    "With 20 units evenly distributed, variance = 0.1, the Absolute residual error was: 0.131492\n",
    "\n",
    "\n",
    "Adding a node in the very end of the interval reduced it somewhat to 0.12314\n",
    "\n",
    "30 units: 0.03243\n",
    "\n",
    "40 units: 0.0313 \n",
    "\n",
    "\n",
    "#### Questions:\n",
    "\n",
    "- What is the lower bound for the number of training examples, N?\n",
    "N must be larger than the number of neurons, n. \n",
    "\n",
    "- What happens with the error if N = n? Why?\n",
    "The error starts increasing. This is because the system is overdetermined. \n",
    "The model can only reach points lying in some fixed plane and can never exactly match y^ if it lies somewhere outside the plane\n",
    "\n",
    "- Under what conditions, if any, does (4) have a solution in this case?\n",
    "Yes, if some equation occurs several times in the system, or if some equations are linear combinations of the others. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.ones((62, 10))\n",
    "b = np.ones((10, 1))\n",
    "a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48019458,  0.81885275,  0.82930642,  0.44603195,  0.87760208,\n",
       "         0.73910216,  0.28358219,  0.58970881,  0.65755535,  0.92755302,\n",
       "         0.05690663,  0.83766092,  0.74423659,  0.60641523,  0.5977054 ,\n",
       "         0.96429012,  0.34903727,  0.93972671,  0.75811998,  0.31139425,\n",
       "         0.27641961,  0.69959149,  0.61484856,  0.66602187,  0.55072389,\n",
       "         0.99419908,  0.35721938,  0.31176724,  0.7327584 ,  0.80676458,\n",
       "         0.52314993,  0.78071668,  0.99320792,  0.10338771,  0.003168  ,\n",
       "         0.39117372,  0.85282454,  0.60804737,  0.74130174,  0.14879854,\n",
       "         0.52707445,  0.87456245,  0.00739324,  0.89133492,  0.85228835,\n",
       "         0.54774499,  0.08255565,  0.9190222 ,  0.63096524,  0.02035962,\n",
       "         0.02691458,  0.38703406,  0.24136002,  0.43103215,  0.67393478,\n",
       "         0.10272357,  0.168787  ,  0.08071918,  0.75065871,  0.2660129 ,\n",
       "         0.09216751,  0.41623994],\n",
       "       [ 0.94281116,  0.68134357,  0.52849469,  0.68262971,  0.03985776,\n",
       "         0.54789456,  0.13471041,  0.63835617,  0.20567221,  0.79349921,\n",
       "         0.7499725 ,  0.39031313,  0.07359711,  0.31104438,  0.43032781,\n",
       "         0.66341305,  0.3295238 ,  0.59517008,  0.06203586,  0.10274319,\n",
       "         0.32626491,  0.62260158,  0.82027095,  0.26176497,  0.68226167,\n",
       "         0.96687653,  0.25281044,  0.65227163,  0.49974978,  0.06907586,\n",
       "         0.41193065,  0.27830984,  0.42730172,  0.8113537 ,  0.12279744,\n",
       "         0.80620352,  0.32738427,  0.24559369,  0.3704491 ,  0.85856856,\n",
       "         0.57590289,  0.34990935,  0.35656298,  0.62420671,  0.70916742,\n",
       "         0.61878954,  0.94617615,  0.5773494 ,  0.44886706,  0.43607221,\n",
       "         0.45288507,  0.48851399,  0.5813197 ,  0.09312517,  0.31341404,\n",
       "         0.5704113 ,  0.70983532,  0.90418341,  0.56870631,  0.06950718,\n",
       "         0.58345658,  0.65057892],\n",
       "       [ 0.05111245,  0.80613667,  0.32462211,  0.28032186,  0.36922002,\n",
       "         0.87015486,  0.86210376,  0.27080011,  0.87413513,  0.09544982,\n",
       "         0.28905634,  0.83598544,  0.46153759,  0.13676034,  0.2621649 ,\n",
       "         0.2119719 ,  0.69345488,  0.09932633,  0.99135016,  0.26333773,\n",
       "         0.05895512,  0.72260892,  0.98433165,  0.87708885,  0.09945118,\n",
       "         0.10577362,  0.60486314,  0.05933038,  0.88853521,  0.39502557,\n",
       "         0.55220425,  0.36189993,  0.7298033 ,  0.17846313,  0.78958815,\n",
       "         0.1729585 ,  0.35187979,  0.37801406,  0.52147123,  0.26214815,\n",
       "         0.3138715 ,  0.50830872,  0.73331639,  0.87422682,  0.78065721,\n",
       "         0.29530104,  0.59375923,  0.52259805,  0.87699343,  0.03525666,\n",
       "         0.76718823,  0.88547567,  0.36998215,  0.37682361,  0.54452813,\n",
       "         0.13782503,  0.94269032,  0.5026945 ,  0.8136885 ,  0.81964331,\n",
       "         0.06350474,  0.8419891 ],\n",
       "       [ 0.03576876,  0.08962873,  0.86195922,  0.40231698,  0.21477362,\n",
       "         0.29867918,  0.34982898,  0.81107049,  0.28184221,  0.99990006,\n",
       "         0.32736814,  0.94901623,  0.34651999,  0.033562  ,  0.04338616,\n",
       "         0.26826361,  0.95920273,  0.71021767,  0.1819457 ,  0.95613962,\n",
       "         0.61274269,  0.53303433,  0.68555753,  0.68470888,  0.33324112,\n",
       "         0.71169899,  0.52222672,  0.9928729 ,  0.2489053 ,  0.91053385,\n",
       "         0.52152158,  0.33421082,  0.73619797,  0.91129972,  0.45469211,\n",
       "         0.76993856,  0.80691436,  0.11439357,  0.33951789,  0.81752559,\n",
       "         0.99357948,  0.37918615,  0.65234669,  0.49570798,  0.21342817,\n",
       "         0.22458999,  0.13427465,  0.76623688,  0.64530754,  0.75187167,\n",
       "         0.64760252,  0.36746523,  0.15608083,  0.99228867,  0.03111784,\n",
       "         0.51811815,  0.61122657,  0.53294947,  0.03855544,  0.67206752,\n",
       "         0.53305664,  0.57568264],\n",
       "       [ 0.38594395,  0.73078687,  0.10322273,  0.20029747,  0.07792825,\n",
       "         0.82815847,  0.06070903,  0.15107815,  0.0859716 ,  0.89607613,\n",
       "         0.51001447,  0.75110183,  0.55606824,  0.53616506,  0.79574526,\n",
       "         0.56388593,  0.17645504,  0.43943533,  0.84580447,  0.1202177 ,\n",
       "         0.4682946 ,  0.56306357,  0.71457376,  0.05955957,  0.75663758,\n",
       "         0.67158698,  0.63713288,  0.91779359,  0.73123666,  0.08433549,\n",
       "         0.7966284 ,  0.0103305 ,  0.05718598,  0.15541087,  0.04213172,\n",
       "         0.03691509,  0.65197182,  0.46619826,  0.19471585,  0.017282  ,\n",
       "         0.1979564 ,  0.87946633,  0.96913446,  0.81585759,  0.78804997,\n",
       "         0.84146242,  0.8056093 ,  0.59721315,  0.15983278,  0.94316054,\n",
       "         0.21330966,  0.08768598,  0.80984987,  0.02722208,  0.9555741 ,\n",
       "         0.0509508 ,  0.82495278,  0.38826084,  0.69511112,  0.44984347,\n",
       "         0.09405061,  0.48529014],\n",
       "       [ 0.85434064,  0.04732281,  0.10495368,  0.20643657,  0.12465678,\n",
       "         0.21760567,  0.12314338,  0.50148691,  0.09237693,  0.29192166,\n",
       "         0.74485818,  0.79868975,  0.98852121,  0.22328595,  0.65549851,\n",
       "         0.41535842,  0.97750969,  0.06157776,  0.26221245,  0.07261548,\n",
       "         0.78530455,  0.90514995,  0.24459518,  0.31683176,  0.84188199,\n",
       "         0.65320539,  0.90714787,  0.97381296,  0.41265339,  0.17405545,\n",
       "         0.46957631,  0.47580406,  0.6256662 ,  0.01941282,  0.3295181 ,\n",
       "         0.87043249,  0.49940992,  0.54483785,  0.45045545,  0.03067233,\n",
       "         0.03250777,  0.16755991,  0.67406839,  0.3236896 ,  0.57437616,\n",
       "         0.95066449,  0.65312118,  0.31256538,  0.53550861,  0.14289613,\n",
       "         0.87439253,  0.12079829,  0.49516565,  0.73399545,  0.49207521,\n",
       "         0.93080393,  0.48438581,  0.8373749 ,  0.83155337,  0.58748566,\n",
       "         0.73210486,  0.00685714],\n",
       "       [ 0.56917728,  0.63615356,  0.8769819 ,  0.16568299,  0.29206006,\n",
       "         0.41822547,  0.76340163,  0.65096943,  0.67587065,  0.55732593,\n",
       "         0.88186536,  0.94630451,  0.34374934,  0.15027382,  0.1479324 ,\n",
       "         0.68845172,  0.28536929,  0.96164183,  0.58857917,  0.34492934,\n",
       "         0.39122039,  0.05096918,  0.60482336,  0.57755082,  0.63801316,\n",
       "         0.96045053,  0.60884573,  0.86279091,  0.05179967,  0.06015222,\n",
       "         0.91491476,  0.68940392,  0.07791644,  0.0566925 ,  0.89417108,\n",
       "         0.53007221,  0.80815267,  0.50129774,  0.82593515,  0.22635872,\n",
       "         0.58585821,  0.85375912,  0.61984364,  0.24506126,  0.95675767,\n",
       "         0.21460456,  0.94070209,  0.68369434,  0.14373489,  0.33970466,\n",
       "         0.18750647,  0.94860368,  0.73534987,  0.08153339,  0.04539438,\n",
       "         0.6745484 ,  0.42301417,  0.61148144,  0.33117751,  0.30448878,\n",
       "         0.20121489,  0.04337474],\n",
       "       [ 0.66849718,  0.42406662,  0.34023534,  0.58083691,  0.45439509,\n",
       "         0.30811211,  0.24665786,  0.29862691,  0.14682833,  0.97757788,\n",
       "         0.65462649,  0.92405604,  0.50354168,  0.56113851,  0.25563261,\n",
       "         0.86871525,  0.11389518,  0.09484302,  0.60086818,  0.91683061,\n",
       "         0.48477578,  0.52155932,  0.04298293,  0.0300271 ,  0.71619726,\n",
       "         0.87537984,  0.31708247,  0.8185082 ,  0.38376935,  0.16057821,\n",
       "         0.94162955,  0.63725507,  0.70851667,  0.7479874 ,  0.92978905,\n",
       "         0.10840038,  0.71172716,  0.96106008,  0.41021893,  0.27841925,\n",
       "         0.22841485,  0.85072006,  0.00889911,  0.80966365,  0.01457496,\n",
       "         0.76876378,  0.23822463,  0.14212937,  0.7893684 ,  0.02604465,\n",
       "         0.43269949,  0.05650658,  0.30247184,  0.96567698,  0.06593092,\n",
       "         0.39448617,  0.17312008,  0.91471202,  0.122891  ,  0.00792246,\n",
       "         0.21217722,  0.99108176],\n",
       "       [ 0.28975645,  0.58885318,  0.51927502,  0.3206331 ,  0.74561182,\n",
       "         0.43312114,  0.05737646,  0.80337731,  0.23708914,  0.82364192,\n",
       "         0.89849342,  0.67448954,  0.09340877,  0.83704229,  0.49306269,\n",
       "         0.54051552,  0.02111187,  0.90736604,  0.23689709,  0.06460288,\n",
       "         0.11960629,  0.40302669,  0.9558407 ,  0.08889301,  0.78043353,\n",
       "         0.60880768,  0.54514081,  0.6224934 ,  0.50054751,  0.04596635,\n",
       "         0.39063089,  0.41422471,  0.83822246,  0.27809602,  0.07100765,\n",
       "         0.19067763,  0.34526933,  0.24868626,  0.5608744 ,  0.53512537,\n",
       "         0.22131554,  0.17378861,  0.89467243,  0.41370884,  0.75481727,\n",
       "         0.73022733,  0.6960509 ,  0.17822811,  0.76913947,  0.35356528,\n",
       "         0.11062616,  0.76513939,  0.29872753,  0.96492207,  0.37057301,\n",
       "         0.56786973,  0.52774805,  0.08628444,  0.9992217 ,  0.79427399,\n",
       "         0.47180453,  0.92899756],\n",
       "       [ 0.91114164,  0.33678642,  0.65348791,  0.46278453,  0.90815313,\n",
       "         0.95148301,  0.23927535,  0.41034754,  0.07325254,  0.62599294,\n",
       "         0.49803847,  0.39190119,  0.91661504,  0.22586104,  0.88946153,\n",
       "         0.91421029,  0.08013592,  0.65112066,  0.84507175,  0.77124065,\n",
       "         0.4327647 ,  0.0431312 ,  0.11901042,  0.10368342,  0.98205268,\n",
       "         0.84671586,  0.1017979 ,  0.19477316,  0.50038169,  0.48818507,\n",
       "         0.7671093 ,  0.7403428 ,  0.6595578 ,  0.81004708,  0.69013338,\n",
       "         0.68989795,  0.82404284,  0.23201526,  0.46713619,  0.66617038,\n",
       "         0.55300509,  0.93999448,  0.27006726,  0.70370819,  0.16492284,\n",
       "         0.97892034,  0.28057184,  0.67657707,  0.55108467,  0.81427875,\n",
       "         0.68864534,  0.8100681 ,  0.08395644,  0.47118625,  0.89746746,\n",
       "         0.61989107,  0.91221542,  0.6134172 ,  0.65702043,  0.61687153,\n",
       "         0.49383206,  0.88646984]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(10, 62)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.73250323,  0.85098012,  0.66279403],\n",
       "       [ 0.32049406,  0.39761901,  0.61799031]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.random.rand(2, 3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((1, 12)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
