{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch mode training using least squares - supervised learning of network weights. \n",
    "\n",
    "\n",
    "- Implement a radial basis function network from scratch. \n",
    "\n",
    "- The network will be used to approximate sin(2x) and square(2x) functions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Support functions for the evaluation\n",
    "\n",
    "def getTrainSet(func = 'sin2x', stepSize = 0.1, noise = True):\n",
    "    ## Returns an 2 x N array of a training set\n",
    "    # Row 0 = inputs and row 1 = targets¨\n",
    "    # stepSize is taken as input, range is fixed to 0 --> 2pi. \n",
    "    N = int(np.floor(2 * np.pi/stepSize)) #Number of datapoints\n",
    "    \n",
    "    train = np.zeros((2,N))\n",
    "    inputs = np.arange(0, N)\n",
    "    np.random.shuffle(inputs)\n",
    "    \n",
    "    if (noise):\n",
    "        noise = 1\n",
    "    else: \n",
    "        noise = 0\n",
    "    \n",
    "    for step, i in enumerate(inputs):\n",
    "        train[0, i] = step*stepSize # Input: will be for example 0, 0.1, 0.2 .. 2pi etc.. \n",
    "        if (func == 'sin2x'): \n",
    "            train[1, i] = np.sin(2*step*stepSize) + noise * np.random.normal(0, np.sqrt(0.1)) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "        elif (func == 'step2x'): \n",
    "            train[1, i] = np.sign(np.sin(2*step*stepSize)) + noise * np.random.normal(0, np.sqrt(0.1)) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "\n",
    "    return train.T\n",
    "\n",
    "def getTestSet(func = 'sin2x', stepSize = 0.1):\n",
    "    ## Returns an 2 x N array of a training set\n",
    "    # Row 0 = inputs and row 1 = targets¨\n",
    "    # stepSize is taken as input, range is fixed to 0 --> 2pi. \n",
    "    N = int(np.floor(2 * np.pi/stepSize)) #Number of datapoints\n",
    "    \n",
    "    test = np.zeros((2,N))\n",
    "\n",
    "    for step in range(N):\n",
    "        test[0, step] = step*stepSize+0.05 # Input: will be for example 0.05, 0.15, 0.25 .. 2pi´0.05 etc.. \n",
    "        if (func == 'sin2x'): \n",
    "            test[1, step] = np.sin(2*step*stepSize+0.05) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "        elif (func == 'step2x'): \n",
    "            test[1, step] = np.sign(np.sin(2*step*stepSize+0.05)) # Target: for example sin(2*0), sin(2*0.1) .. sin(2*2pi) etc..\n",
    "\n",
    "    return test.T\n",
    "\n",
    "def getBallisticTrainSet():\n",
    "    data = np.loadtxt('data/ballist.dat', dtype=float)\n",
    "    inp = []\n",
    "    target = []\n",
    "    for d in data[:,0:2]:\n",
    "        inp.append((d[0], d[1]))\n",
    "    \n",
    "    for d in data[:,2:4]:\n",
    "        target.append((d[0], d[1]))\n",
    "    inp = np.array(inp)\n",
    "    target = np.array(target)\n",
    "    \n",
    "    return inp, target\n",
    "\n",
    "def getBallisticTestSet():\n",
    "    data = np.loadtxt('data/balltest.dat', dtype=float)\n",
    "    inp = []\n",
    "    target = []\n",
    "    for d in data[:,0:2]:\n",
    "        inp.append((d[0], d[1]))\n",
    "    \n",
    "    for d in data[:,2:4]:\n",
    "        target.append((d[0], d[1]))\n",
    "    inp = np.array(inp)\n",
    "    target = np.array(target)\n",
    "    return inp, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBF:\n",
    "    def __init__(self, n = 12, variance = 0.1, learning_rate = 0.1, maxinput_x = 1, maxinput_y = 1):\n",
    "        self.n = n # the number of nodes\n",
    "        self.variance = 0.1 ## Same variance for all nodes\n",
    "        # self.units = np.random.rand(1, n) * maxinput # random unit position in the input space\n",
    "        # self.units = np.array([0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6]) # unit positions \n",
    "        \n",
    "        # Place units with even spaces. each has an x and y coordinate. \n",
    "        x_cords = np.arange(0, maxinput_x, maxinput_x/(self.n)) \n",
    "        print(x_cords)\n",
    "        self.units = []\n",
    "        # the units are an array of tuples\n",
    "        for i in range(self.n):\n",
    "            self.units.append((x_cords[i], maxinput_y/2))\n",
    "        \n",
    "        \n",
    "        self.units = np.array(self.units)\n",
    "\n",
    "        self.n = self.units.shape[0]\n",
    "        self.w = []\n",
    "        #for i in range(n): \n",
    "        #    self.w.append((np.random.rand(), np.random.rand()))\n",
    "        #self.w = np.array(self.w)\n",
    "        self.w = np.random.rand(self.n) # random weights for each node\n",
    "        self.lr = learning_rate\n",
    "        print(\"Initiated weights: \")\n",
    "        print(self.w)\n",
    "        #\n",
    "        #print(\"Initiated units: \")\n",
    "        #print(self.units)\n",
    "        #print(self.n)\n",
    "    #\n",
    "    def error(self, f_approx, f):\n",
    "        # the average error (with direction +/-)\n",
    "        if not (f_approx.shape == f.shape): \n",
    "            raise Exception('f_approx and f shapes mismatch. f_approx: {}, f: {} '.format(f_approx.shape, f.shape))\n",
    "\n",
    "        # error = (phi(x) - target)^2\n",
    "        return np.average(f_approx - f)\n",
    "    \n",
    "    def res_error(self, f_approx, f):\n",
    "        # the residual error (absolute)\n",
    "        if not (f_approx.shape == f.shape): \n",
    "            raise Exception('f_approx and f shapes mismatch. f_approx: {}, f: {} '.format(f_approx.shape, f.shape))\n",
    "\n",
    "        # error = (phi(x) - target)^2\n",
    "        return np.average(np.abs(f_approx - f))            \n",
    "    \n",
    "    def predict(self, inp):\n",
    "        # takes an input inp and returns predictions\n",
    "        # do f^ = phi(x) * w.T\n",
    "        x = inp#.dot(np.ones((2, self.n))) # m x 1 * 1 x n --> m x n\n",
    "        \n",
    "        # 1 x n * n x 2\n",
    "        phi_x = []\n",
    "        for i in range(self.n): # for each node\n",
    "            res = self.phi_tup(x, i)\n",
    "            phi_x.append(res)\n",
    "        phi_x = np.array(phi_x).T\n",
    "        f_approx = np.array(phi_x.dot(self.w))\n",
    "        print(\"phi_x:\")\n",
    "        print(phi_x.shape)\n",
    "        print(\"self.w\")\n",
    "        print(self.w.shape)\n",
    "        print(\"Predicted: \")\n",
    "        print(f_approx)\n",
    "        print(\"from input:\")\n",
    "        print(inp)\n",
    "        return f_approx\n",
    "    \n",
    "    def fit_lsq(self, inp, f):\n",
    "        # x is the input. Shape: inputs x 1\n",
    "        # f is the true value of the function (aka the target), same shape\n",
    "        if not (inp.shape == f.shape): \n",
    "            raise Exception('inp and f shapes mismatch. inp: {}, f: {} '.format(inp.shape, f.shape))\n",
    "    \n",
    "\n",
    "        # We want x to be a matrix with shape: inputs x neurons\n",
    "        x = inp.dot(np.ones((1, self.n))) # inp x 1 * 1 x n --> inp x n\n",
    "        \n",
    "        \n",
    "        # get phi(x)\n",
    "        self.phi_x = self.phi_matrix(x)\n",
    "\n",
    "        # we obtain the w that minimizes the error by solving: \n",
    "        # phi(x).T * phi(x) * w = phi(x).T * f\n",
    "        # --> w = (phi(x).T * phi(x))^-1 * phi(x).T * f        \n",
    "        self.w = np.linalg.inv(self.phi_x.T.dot(self.phi_x)).dot(self.phi_x.T).dot(f)\n",
    "        \n",
    "    \n",
    "    def fit_delta(self, inp, f):\n",
    "        # x is the input. Shape: inputs x 1\n",
    "        # f is the true value of the function (aka the target), same shape\n",
    "        if not (inp.shape == f.shape): \n",
    "            raise Exception('inp and f shapes mismatch. inp: {}, f: {} '.format(inp.shape, f.shape))\n",
    "            \n",
    "        self.phi_x = []\n",
    "        # compute phi(x)\n",
    "        for i, unit in enumerate(self.units):\n",
    "            self.phi_x.append((self.phi(inp[0], unit[0]), inp[1], unit[1]))\n",
    "        \n",
    "        self.phi_x = np.array(self.phi_x)\n",
    "        \n",
    "        # make a prediction\n",
    "        f_approx = self.predict(inp)\n",
    "        \n",
    "        # compute the error\n",
    "        e = self.error(f_approx, f)\n",
    "        \n",
    "        # find delta w\n",
    "        self.dw = -1 * self.lr * e * self.phi_x.T\n",
    "        \n",
    "        print(self.dw.shape)\n",
    "        #update weights\n",
    "        self.w += self.dw\n",
    "            \n",
    "    def cl_vanilla_update(self, sample, learning_rate):\n",
    "        # find the \"winner\" of the units (the one closest to the random sample)\n",
    "        unit_distance = np.abs(self.units - sample)\n",
    "        winner_idx = np.argmin(unit_distance)\n",
    "        \n",
    "        # print(\"CL. Random Sample: {} Winner: {}\".format(sample, self.units[winner_idx]))\n",
    "        \n",
    "        # how far away is the winner's position from the sample? \n",
    "        dp = -1 * learning_rate * (self.units[winner_idx] - sample)\n",
    "        \n",
    "        # update the winner's position to be slightly closer to the random sample\n",
    "        self.units[winner_idx] += dp\n",
    "\n",
    "    def cl_multi_update(self, sample, learning_rate, winners = 5):\n",
    "        # by looking for multiple winners, we avoid dead units. \n",
    "        \n",
    "        # find multiple \"winners\" of the units (the one closest to the random sample)\n",
    "        unit_distance = np.abs(self.units - sample)\n",
    "        \n",
    "        for i in range(winners):\n",
    "            winner_idx = np.argmin(unit_distance)\n",
    "            unit_distance[winner_idx] = np.inf # set this distance to inf so its not selected again     \n",
    "            \n",
    "            # how far away is the winner's position from the sample? \n",
    "            dp = -1 * learning_rate * (self.units[winner_idx] - sample)\n",
    "            \n",
    "            # Checked w. this print, seems to work\n",
    "            # print(\"CL. Random Sample: {} Winner: {}. Diff: {}. Moving {} to: {}\".format(sample, self.units[winner_idx], dp, winner_idx, self.units[winner_idx]+dp))\n",
    "\n",
    "            # update the winner's position to be slightly closer to the random sample\n",
    "            self.units[winner_idx] += dp\n",
    "            \n",
    "\n",
    "    def phi(self, x, i): \n",
    "        return np.exp((-(np.linalg.norm(x-i))**2)/(2*np.square(self.variance)))\n",
    "        \n",
    "    def phi_tup(self, tup, i):\n",
    "        unit = self.units[i]\n",
    "        phi_tup = np.array((self.phi(tup[0], unit[0]), self.phi(tup[1], unit[1])))\n",
    "        return phi_tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train inputs example:\n",
      "[[ 0.896  0.54 ]\n",
      " [ 0.279  0.859]\n",
      " [ 0.307  0.403]\n",
      " [ 0.974  0.546]\n",
      " [ 0.069  0.903]]\n",
      "[ 0.      0.0448  0.0896  0.1344  0.1792  0.224   0.2688  0.3136  0.3584\n",
      "  0.4032  0.448   0.4928  0.5376  0.5824  0.6272  0.672   0.7168  0.7616\n",
      "  0.8064  0.8512  0.896   0.9408  0.9856  1.0304  1.0752  1.12    1.1648\n",
      "  1.2096  1.2544  1.2992  1.344 ]\n",
      "Initiated weights: \n",
      "[ 0.70369669  0.7904645   0.88295892  0.3671288   0.7116486   0.71358653\n",
      "  0.4233931   0.07494317  0.76006148  0.19779033  0.86137729  0.7630675\n",
      "  0.93452646  0.82746502  0.04519396  0.96131806  0.67138817  0.06941045\n",
      "  0.66830021  0.14351518  0.11236137  0.86337991  0.52413626  0.20603774\n",
      "  0.2620297   0.56514146  0.18926909  0.55928898  0.42784694  0.82868628]\n",
      "phi_x:\n",
      "(2, 30)\n",
      "self.w\n",
      "(30,)\n",
      "Predicted: \n",
      "[  2.26751535e+00   5.22370189e-08]\n",
      "from input:\n",
      "[ 0.85   0.019]\n",
      "(3, 30)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (30,) doesn't match the broadcast shape (3,30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-92a0f7d1f2fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mwinners_multi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# batch(units, trainset, testset, width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mmod1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_nocl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mmod2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_cl_van\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mmod3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_cl_mul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwinners_multi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-178-92a0f7d1f2fe>\u001b[0m in \u001b[0;36mdelta\u001b[0;34m(n, variance, learning_rate, epochs, winners)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwinners\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-177-d2416da433f7>\u001b[0m in \u001b[0;36mfit_delta\u001b[0;34m(self, inp, f)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m#update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcl_vanilla_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (30,) doesn't match the broadcast shape (3,30)"
     ]
    }
   ],
   "source": [
    "def delta(n, variance = 0.1, learning_rate = 0.1, epochs = 20, winners = 0):\n",
    "    # Get datasets\n",
    "    train_inp, train_target = getBallisticTrainSet()\n",
    "    print(\"train inputs example:\")\n",
    "    print(train_inp[0:5])\n",
    "\n",
    "    # Get test set\n",
    "    test_inp, test_target = getBallisticTestSet()\n",
    "    \n",
    "    model = RBF(n, variance, learning_rate, maxinput_x = np.max(train_inp[0] * 1.5), maxinput_y = np.max(train_inp[1] * 1.5)) # Taking 50% extra input space\n",
    "    \n",
    "\n",
    "    for epoch in range(epochs): \n",
    "\n",
    "        # Shuffle data\n",
    "        idx = np.random.permutation(train_inp.shape[0])\n",
    "        train_inp = train_inp[idx]\n",
    "        train_target = train_target[idx]\n",
    "        \n",
    "        for i, inp in enumerate(train_inp):\n",
    "            sample = inp\n",
    "            target = train_target[i]\n",
    "            model.fit_delta(sample, target)\n",
    "        \n",
    "        if (winners > 0): \n",
    "            # Update units through competetive learning\n",
    "            rand = np.random.choice(train_inp[:, 0])\n",
    "            model.cl_multi_update(rand, 0.1, winners)\n",
    "        \n",
    "        # Make predictions\n",
    "        pred = model.predict(test_inp)\n",
    "        # test error\n",
    "        previous_error = e\n",
    "        e = model.res_error(pred, test_target)\n",
    "        epoch += 1\n",
    "        if (epoch % 5 == 0):\n",
    "            print(\"Epoch {}, residual error: {}, dw: {}\".format(epoch, e, np.average(model.dw)))\n",
    "    print(\"Epoch {}, residual error: {}, dw: {} \".format(epoch, e, np.average(model.dw)))\n",
    "    return model, e\n",
    "    \n",
    "\n",
    "\n",
    "units = 30\n",
    "width = 0.1\n",
    "lr = 0.25\n",
    "epochs = 100\n",
    "winners_multi = 5\n",
    "# batch(units, trainset, testset, width)\n",
    "mod1, noise_nocl = delta(units, width, lr, epochs)\n",
    "mod2, noise_cl_van = delta(units, width, lr, epochs, winners = 1)\n",
    "mod3, noise_cl_mul = delta(units, width, lr, epochs, winners = winners_multi)\n",
    "\n",
    "\n",
    "print(\"Units: {}. Width: {}. Learning rate: {}. Winners in multi CL: {}\".format(units, width, lr, winners_multi))\n",
    "print(\"Ballistic data. No CL: {}\".format(noise_nocl))\n",
    "print(\"Ballistic data. Vanilla CL: {}\".format(noise_cl_van))\n",
    "print(\"Ballistic data. Multi CL: {}\".format(noise_cl_mul))\n",
    "\n",
    "## Compare units\n",
    "## Scatter Plot\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(211)\n",
    "ax.scatter(mod1.units, np.ones(mod1.units.shape)*1.5, marker = \"o\", c = 'green', label = \"No CL\")\n",
    "ax.scatter(mod2.units, np.ones(mod1.units.shape), marker = \"o\", c = 'red', label = \"Vanilla CL\")\n",
    "ax.scatter(mod3.units, np.ones(mod1.units.shape)*0.5, marker = \"o\", c = 'blue', label = \"Multi CL\")\n",
    "\n",
    "ax.set(title='',\n",
    "        xlabel = \"Unit pos\",\n",
    "      ylim = (0, 2))\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
